%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LaTeX Vorlage: Mathematische Texte
%
% Quelle: http://www.mi.uni-koeln.de/wp-MIEDV/% Datum: Juli 201% Copyright Universität zu Köln
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[12pt,a4paper,twoside, open=right]{scrreprt}

\addtokomafont{sectioning}{\rmfamily}
%\usepackage[ngerman]{babel}% deutsches Sprachpaket wird geladen
\usepackage[ngerman,english]{babel}% englisches Sprachpaket wird geladen
\usepackage{tabularx}
%\usepackage{lmodern}% Für die Schrift
\usepackage[T1]{fontenc} % westeuropäische Codierung wird verlangt
\usepackage[utf8]{inputenc}% Umlaute werden erlaubt
\usepackage[usenames]{color} % Erlaubt die Benutzung der namen im Farbpaket und deren Änderung
%\usepackage{showkeys} % Labels anzeigen
\usepackage{amsmath} % Erweiterung für den Mathe-Satz
\usepackage{amssymb} % alle Zeichen aus msam und msmb werden dargestellt
\usepackage{framed}
\usepackage[german]{fancyref}
\usepackage{listings}
\usepackage{tikz} % Erlaubt es mit tikz zu zeichnen
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{groupplots}
\usepgfplotslibrary{dateplot}
\usepgfplotslibrary{external} 
\tikzexternalize
\usepackage{color}
\usepackage{pdfpages}
\definecolor{mygreen}{RGB}{28,172,0} % Define colour
\definecolor{mylilas}{RGB}{170,55,241}
\usepackage{graphicx} % Graphiken und Bilder können eingebunden werden
\usepackage{multirow} % erlaubt in einer Spalte einer Tabelle die Felder in mehreren Zeilen zusammenzufassen
\usepackage{enumerate} % erlaubt Nummerierungen 
\usepackage{url} % Dient zur Auszeichnung von URLs; setzt die Adresse in Schreibmaschinenschrift.
\usepackage[center]{caption}  % Bildunterschrift wird zentriert
\usepackage{subfigure} % mehrere Bilder können in einer figure-Umgebung verwendet werden
\usepackage{longtable} % Diese Umgebung ist ähnlich definiert wie die tabular-Umgebung, erlaubt jedoch mehrseitige Tabellen.
\usepackage{paralist} % Modifikation der bereits bestehenden Listenumgebungen
\usepackage{amsthm} % erlaubt die Benutzung von eigenen Theoremen
\usepackage{hyperref} % Links und Verweise werden innerhalb von PDF Dokumenten erzeugt
\usepackage{wrapfig} % Das Paket ermöglicht es von Schrift umflossene Bilder und Tabellen einzufügen.
%\numberwithin{equation}{section} % Nummerierungen der Gleichungen, die durch equation erstellt werden, sind gebunden an die section
\usepackage{latexsym} % LaTeX-Symbole werden geladen

\usepackage{tabularx} % Erlaubt Tabellen 
\usepackage{algorithm} % Erlaubt Pseudocode
\usepackage{algorithmic}
\usepackage{color} % Farbpaket wird geladen
\usepackage{stmaryrd} % St Mary Road Symbole werden geladen
\usepackage{csquotes}
\usepackage{bm}
\usepackage{todonotes}
\usepackage{lipsum}
\usepackage{multicol}

% Hier werden neue Theorems erstellt.
\theoremstyle{definition}
\newtheorem{auf}{Aufgabe}
\newtheorem{rem}[auf]{Remark}
\newtheorem{defn}[auf]{Definition}
\newtheorem{bsp}[auf]{Example}
\newtheorem{notation}[auf]{Notation}
\theoremstyle{plain}
\newtheorem{kor}[auf]{Corollary}
\newtheorem{sa}[auf]{Theorem}
\newtheorem{lem}[auf]{Lemma}
\newtheorem{alg}[auf]{Algorithm}
\DeclareMathOperator*{\esssup}{ess\,sup} % essentiellen Supremums
\DeclareMathOperator{\spn}{span} % Span
\DeclareMathOperator{\supp}{supp} % Träger
\DeclareMathOperator{\ddiv}{div} % divergenz
\newcommand{\abs}[1]{\left\vert #1\right\vert}
\newcommand{\dotp}[2]{\left\langle #1,#2\right\rangle}
\newcommand{\rr}{\mathbb{R}}
\newcommand{\g}{~\textgreater ~}
\newcommand{\ls}{~\textless ~}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newcommand{\cc}{\mathbb{C}}
\newcommand{\kk}{\mathbb{K}}
\newcommand{\nn}{\mathbb{N}}
\newcommand{\qq}{\mathbb{Q}}
\newcommand{\e}{\varepsilon\g 0~}
\newcommand{\fe}{\forall \e}
\newcommand{\so}{\sum_{k=0}^{n}}
\newcommand{\si}{\sum_{k=1}^{n}}
\newcommand{\soi}{\sum_{k=0}^{\infty}}
\newcommand{\sii}{\sum_{k=1}^{\infty}}
\newcommand{\de}{\mathrm{d}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\lpnorm}[1]{\left(\int\abs{#1}^2\D\Omega \right)^{1/2}}
\newcommand{\ltnorm}[1]{\norm{#1}_{\mathrm{L}^2}}
\newcommand{\bfu}{\bm{u}}
\newcommand{\bff}{\bm{f}}
\newcommand{\bfB}{\bm{B}}
\newcommand{\bfb}{\bm{b}}
\newcommand{\bfs}{\bm{s}}
\newcommand{\bfC}{\bm{C}}
\newcommand{\bfx}{\bm{x}}
\newcommand{\bfR}{\bm{R}}
\newcommand{\tpne}{\tilde\phi_{n+1}}
\newcommand{\tpn}{\tilde\phi_{n}}
\newcommand{\D}{\mathop{}\!\mathrm{d}}
\floatname{algorithm}{Algorithmus}
\renewcommand{\thesubfigure}{\thefigure.\arabic{subfigure}}
\addto{\captionsenglish}{\renewcommand{\bibname}{References}}
\lstset{language=Matlab,
    basicstyle={\scriptsize \ttfamily},
    breaklines=true,
    morekeywords={matlab2tikz},
    keywordstyle=\color{blue},
    morekeywords=[2]{1}, 
    keywordstyle=[2]{\color{black}},
    identifierstyle=\color{black},
    stringstyle=\color{mylilas},
    commentstyle=\color{mygreen},
    showstringspaces=false, %without this there will be a symbol in the places where there is a space
    numbers=left,
    numberstyle={\tiny \color{black}}, % size of the numbers
    numbersep=9pt, % this defines how far the numbers are from the text
    emph=[1]{for,end,break},
    emphstyle=[1]\color{red}, %some words to emphasise
}
\makeatletter
\renewcommand{\p@subfigure}{}
\renewcommand{\@thesubfigure}{\thesubfigure:\hskip\subfiglabelskip}
\makeatother
\begin{document}
% Hier wird die Titelseite erstellt
\begin{titlepage}
\pagestyle{empty}
\begin{center}
\newcommand{\HRule}{\rule{\linewidth}{0.7mm}}
\textsc{\LARGE University of Cologne }\\ [0.4cm]
\textsc{ Department of Mathematics} \\[1.5cm]
\includegraphics[width=0.45\textwidth]{uni}\\[1.5cm]  % Uni-Logo wird geladen
\HRule \\[0.4cm]
{ \huge \bfseries Numerical Solution of Integro-Differential equations}\\[0.4cm]
\HRule \\[1cm]
\textsc{\Large Master's thesis}\\[2mm]
\textsc{\today}\\[10mm]
\textsc{in cooperation with the German Aerospace Center (SC-HPC)}\\[1.0cm]
\includegraphics[width=0.45\textwidth]{DLR-Logo-full}\\[1.0cm]


  




\begin{center}

\textsc{\Large Nils Dornbusch} \\[3pt]
\textsc{\Large first examiner: Prof. Dr-Ing. Gassner}
\end{center}
\end{center}
\end{titlepage}
\begin{otherlanguage}{ngerman}
  

\chapter*{Danksagung}
Als Erstes möchte ich mich bei Herrn Professor Gassner für die sehr gute Betreuung und die Flexibilität bedanken, dass ich in Kooperation mit dem Deutschen Zentrum für Luft- und Raumfahrt meine Masterarbeit anfertigen konnte. Darüber hinaus gilt mein Dank Herrn Dr. Basermann für die Möglichkeit, Betreuung für meine Masterarbeit in der Abteilung High-Performance Computing (SC-HPC) zu erhalten. Genau dieser Abteilung möchte ich vom ganzen Herzen für die tolle kollegiale Zusammenarbeit schon vor Beginn meiner Masterarbeit und währenddessen sowie die vielfältige Unterstützung bedanken. Insbesondere Herrn Dr. Kontak und Herrn Dr. Knechtges gilt meine große Wertschätzung für die viele Zeit, das Engagement und die große fachliche und menschliche Unterstützung in dieser Zeit. Natürlich möchte ich mich in diesem Zuge auch bei Herrn Professor Sperl für die Bereitstellung des Themas bedanken. \par
Zusätzlich bedanke ich mich noch bei meiner Familie, meinen Freunden und Kommilitonen und meiner Freundin für ihre Geduld und ihr Verständnis.
\\[1cm]
Köln, \today 
\\[1cm]
Nils Dornbusch
\end{otherlanguage}
\newpage
\tableofcontents
\newpage
\chapter{Introduction}
This work aims to provides an analysis of the integro-differential equations which occur while modeling the behavior of non-\textsc{Newtonian} fluids. The motivation to model these fluids arises when studying for example liquid glass or granular flow. This is often needed in space applications. This work should be seen as a first step in studying these governing equations. The long term goal is to develop a method to simulate an arbitrary non-\textsc{Newtonian} fluid in three spatial dimensions. Such a method does not exist as of now. An approach taken in \cite{Hulsen2001} and \cite{Hulsen2018} is the deformation fields method, which we will follow in part. However, not the whole method is suited for our needs. This is due to the fact that this method would result in the calculation of an integral in each timestep even if the timesteps are chosen carefully. What is even worse is that the more timesteps one calculates the more expensive the integral becomes. As the full system of equations is five-dimensional, one can imagine that this is not efficient for a reasonable number of degrees of freedom. This works aims to provide a possibility to reduce the calculation effort. However, as this is a master's thesis only a reduced three-dimensional system will be considered. To obtain this reduction, sensible assumptions will be taken.
\\
\par 
The goal is that every reader that is proficient in Mathematics on a master's level is able to follow the arguments given in this work. To achieve this, some basic mathematical facts will be given in the beginning of this work. We will also introduce some notation that will be used. The second chapter will deal with the Physics behind the governing equation. As this is a mathematical work most of the time we will only discuss ideas rather than discussing the whole physical theory. After that we will reduce the system of equations from three to two spatial dimensions. The elimination of a second time variable will take place in chapter 4, where we will use the \textsc{Laplace} transform. Chapter 4 will deal with all aspects of numerics. At first we will discretize the continuous equations from chapter 3 in space and time. After we have built the numerical scheme we will study the convergence and other properties of the algorithm. Some aspects regarding the implementation will also be discussed.\\
\par
Chapter 5 will mostly take a look at a different integro-differential equation. It can be found in \cite{Goetze1995}. The equation from \cite{Goetze1995} is easier in the sense that is does not have a spatial component or multiple variables but it is as complex as the full system regarding the calculation of the integral. Therefore it is much easier to study the simpler equation and try out different ideas, which can then be transfered back to the original problem. This is necessary, because it turns out that we can only deduce a better algorithm under the assumptions we took to reduce the five-dimensional system of equations. \par
In the last chapter we will conclude all results and give an outlook on what could be next sensible points to consider.
%\par 
%The biggest problem when trying to implement these equation lies in the Integral over older timesteps and the appearence of another time dimension, which we call the \enquote{age dimension}. But more on that later on.\\
%We will take the following steps to study said equations:
%\begin{itemize}
%    \item theoretical derivation of the Navier-Stokes-Equations for the non-Newtonian stress tensor
%    \item discussion of different spatial and time discretization methods
%    \item challenges in the implementation
%    \item some application with different complexity 
%\end{itemize}
%For the sake of simplicity we will use the well known framework FEniCS \cite{Alnaes2012a}\cite{AlnaesBlechta2015a}\cite{AlnaesEtAl2012}\cite{AlnaesLoggEtAl2012a} which uses the underlying DOLFIN library \footnote{citation needed} and we will make assumptions that reduce the complexity of the problem. \par 
%At the end of this work we would like to answer the question: \enquote{Is this numerical method worth to try with the full system in 5-dimensions (3 spatial + 1 time  + 1 age dimension) in exa-scale systems?}\par 
%So without further ado let us dive into the matter!
\newpage
\chapter{Mathematical basics}
In this chapter, various definitions and theorems are presented, which will be used extensively throughout this work. Most of them are just a recap of well-known theorems and are therefore presented without proof. The interested reader may follow the literature referenced in each section.
\section{Basics and notation}
In the beginning, we will quickly state basic mathematical facts and introduce some notation, which we will use throughout this work. Most of this should be self-explanatory.
\begin{notation}
    We will use $\nn$ as the natural numbers starting from 1, $\nn_0$ represent the natural numbers starting from 0. $\rr,\cc,\qq$ denote the real, complex and rational numbers. With $\kk$ we denote a field, which can be $\rr$ or $\cc$. $\rr^+_0$ shall denote $[0,\infty)$.
\end{notation} 
\begin{defn}[Essential supremum]
    Let $X\subset\rr^n$ for $n\in\nn$ and $f\colon X\to \rr$ be a function. 
    We call 
    \begin{equation}
        \esssup_{x\in X}f(x):=\inf\{a\in\rr\colon f(x)\le a\quad\text{almost everywhere}\}
    \end{equation}
    the essential supremum of $f$. 
\end{defn}
\begin{notation}
    We use $\nabla f$ to denote the spatial gradient of $f$. For the \textsc{Laplacian} operator we use the standard symbol $\Delta$. 
\end{notation}
\begin{notation}[Multi-index notation]
    To generalize the idea of an integer index, we will consider $\alpha=(a_1,\dotsc,a_n)$, where $a_i\in\nn_0$ for all $i=1,\dotsc,n$. We call $\alpha$ a multi-index. We define $\abs{\alpha}=\sum_{i=1}^na_i$. Later on $\sum_{\abs{\alpha}\le n}$ will appear for a fixed $n\in\nn$. By this we denote the sum over all possible $\alpha$. We will also encounter $D^\alpha$, where $D$ is the standard differential operator. We define \begin{equation}
        D^\alpha=\frac{\partial^{\abs{\alpha}}}{\partial x_1^{a_1}\dotsb\partial x_n^{a_n}}.
    \end{equation}
\end{notation}
\section{Functional analysis}
\label{sec:funcana}
Here, we cover some basics of functional analysis that are necessary for this work and especially the finite element method. We will follow \cite{Ganesan2017} for this.
\begin{defn}[Norm]
    Let $X$ be a $\kk$ vector space. A mapping $\norm{\cdot}\colon X\to\rr$ is called a \emph{norm} on $X$ if 
    \begin{align}
        1. &\norm{x}=0 \Leftrightarrow x=0 &&\forall x\in X  &&\text{(positive definite)},\\
        2. &\norm{\lambda x}=\abs{\lambda}\norm{x} &&\forall x\in X,\lambda\in\kk &&\text{(homogeneous)},\\
        3. &\norm{x+y}\le\norm{x}+\norm{y}&&\forall x,y\in X &&\text{(triangle inequality)}.
    \end{align}

    We call the pair $(X,\norm{\cdot})$ a \emph{normed space}.
\end{defn}
\begin{rem}
    It follows directly from the definition that $\norm{x}\ge 0$ for all $ x\in X$.
\end{rem}
\begin{defn}[\textsc{Cauchy} sequence]
    A sequence $(x_n)_{n\in\nn}$ is called \emph{\textsc{Cauchy} sequence} if
    \begin{equation}
         \forall\varepsilon>0~\exists n_0(\varepsilon)\in\nn\colon \forall m,n>n_0\colon\norm{x_m-x_n}<\varepsilon.
    \end{equation}
\end{defn}
\begin{defn}[Convergence]
    A sequence $(x_n)_{n\in\nn}$ converges to $x\in X$ if 
    \begin{equation}
        \forall\varepsilon>0~\exists n_0(\varepsilon)\colon \forall n>n_0 \colon \norm{x_n -x}<\varepsilon.
    \end{equation}
\end{defn}
It is well-known that a \textsc{Cauchy} sequence does not converge in general. The class of spaces, for which this is true, is given in the following definition.
\begin{defn}
    A normed space $(X, \norm{\cdot})$ is called \emph{complete} if every \textsc{Cauchy} sequence in $X$ converges in $X$. A complete normed space is also called a \textsc{Banach} \emph{space}.
\end{defn}
From now on let $\Omega$ be an open and bounded subset of $\rr^n$, with $n\in\nn$
\begin{defn}
    For a function $f\colon\Omega\to\rr$ and $p\in[1,\infty)$ we define the norm
     \begin{equation}
    \norm{f}_{p}:=\left(\int_\Omega\abs{f}^p\D\Omega\right)^{1/p}
    \end{equation}
    and
     \begin{equation}
    \norm{f}_{\infty}:=\esssup\{\abs{f(x)}\colon x\in\Omega\}.
    \end{equation}
    However, this is only a norm if we identify functions, which only differ on sets of zero measure. As usual the sets of equivalence classes of almost everywhere identical functions for which $\norm{f}_p<\infty$ is denoted by $\mathrm{L}^p(\Omega)$.
\end{defn}
\begin{lem}[\textsc{Minkowski}'s inequality]
    For $f,g\in L^p(\Omega)$ and $p\in[1,\infty]$, we have
    \begin{equation}
        \norm{f+g}_p\le\norm{f}_p+\norm{g}_p
    \end{equation}
\end{lem}
\begin{sa}
    The space $L^p(\Omega)$, $p\in[1,\infty]$ is a \textsc{Banach} space.
\end{sa}
\begin{defn}
    Let $V$ be a $\kk$ vector space. A mapping $\dotp{\cdot}{\cdot}\colon V\times V\to\rr$ is called an \emph{inner product} or \emph{dot product} if 
    \begin{enumerate}
        \item $\dotp{u}{u} \ge 0 \quad \forall u\in V$ (positive definite),
        \item $\dotp{u}{u} = 0 \Leftrightarrow u=0 $  (strictly positive),
        \item $\dotp{u}{v} = \overline{\dotp{v}{u}}   \quad\forall u,v\in V$ (conjugate symmetric),
        \item $\dotp{u}{\lambda v} = \lambda\dotp{u}{v} \quad\forall u,v\in V,\lambda\in\kk$ (homogeneous in second argument),
        \item $\dotp{u}{v+w} =\dotp{u}{v}+\dotp{u}{w} \quad\forall u,v\in V$ (linear in second argument).
    \end{enumerate}
\end{defn}
\begin{rem}
    In the case that $V$ is a real-valued vector space, the inner product is linear and homogeneous in both arguments. In case $V$ is a complex-valued vector space we obtain linearity in the second argument. Let $\lambda\in\kk$ and $u,v,w\in V$, then
    \begin{equation}
        \dotp{\lambda u +v}{w}=\overline{\dotp{w}{\lambda u + v}}=\overline{\lambda}\dotp{u}{w}+\dotp{v}{w}.
    \end{equation}
\end{rem}
\begin{sa}
    Let $V$ be a vector space and $\dotp{\cdot}{\cdot}$ be an inner product. By setting $\norm{v}_V:=\sqrt{\dotp{v}{v}}$, we obtain a norm. Thus every vector space with an inner product is a normed space.
\end{sa}
\begin{defn}
    A complete vector space with an inner product is called a \emph{\textsc{Hilbert} space}.
\end{defn}
\begin{bsp}
    $V=\mathrm{L}^2(\Omega)$ with the inner product
    \begin{equation}
    \dotp{f}{g}:=\int_\Omega f(x)g(x)\D x
    \end{equation}
    is a \textsc{Hilbert} space.
\end{bsp}
\begin{sa}[\textsc{Cauchy-Schwarz} inequality]
    \label{sa:Schwarz}
    Let $V$ be a vector space. Then 
    \begin{equation}
        \abs{\dotp{u}{v}}\le\norm{u}_V\norm{v}_V\quad \forall u,v\in V.
    \end{equation}
\end{sa}

\begin{notation}
    We write $\mathrm{C}^k(\Omega)$, $k\in\nn\cup\{\infty\}$, for the space of $k$-times differentiable functions on $\Omega$. $\mathrm{C}^0(\Omega)$ shall be the space of continuous functions on $\Omega$.
\end{notation}
\begin{defn}
    The \emph{support} of a function $f\colon \Omega\to\rr$ is defined by 
    \begin{equation}
        \supp f = \overline{\{x\in\Omega\colon f(x)\neq 0\}}.
    \end{equation}
\end{defn}
\begin{notation}
    In the following we will often use functions with compact support, so we introduce the notation
    \begin{equation}
        \mathrm{C}^k_0(\Omega)=\{f\in \mathrm{C}^k(\Omega)\colon \supp f \text{ is compact in }\Omega \},
    \end{equation}
    where we mean \enquote{compact} in the topological sense, so in our cases bounded and closed.
\end{notation}
\begin{rem}
    \label{rem:testfzero}
    One can proof that if $f\in \mathrm{C}^k_0$, then $f$ tends to zero on the boundary $\partial\Omega$. This motivates the notation.
\end{rem}
\begin{defn}
    We define 
    \begin{equation}
        \mathrm{L}^1_{\mathrm{loc}}(\Omega):=\{f\colon\Omega\to\rr\colon f\in \mathrm{L}^1(A) \text{ for all compact} A\subset\Omega \},
    \end{equation}
    as the space of \emph{locally integrable functions}.
\end{defn}
\begin{bsp}
    The space $\mathrm{L}^1_\mathrm{loc}$ is a true superset of $\mathrm{L}^1$. Consider $f(x)=\frac{1}{x}$ on $(0,1)$. $f$ belongs to $\mathrm{L}^1_\mathrm{loc}(0,1)$, but not to $\mathrm{L}^1(0,1)$. 
\end{bsp}
\begin{defn}
    \label{defn:weakderivative}
    Let $\alpha\in\nn^n_0$ be a multi index. A function $f\in \mathrm{L}^1_{\mathrm{loc}}(\Omega)$ has a \emph{weak derivative} $\nu$, which is denoted by $D^\alpha f\in \mathrm{L}^1_\mathrm{loc}(\Omega)$ if $\forall \varphi\in \mathrm{C}_0^\infty$
    \begin{equation}
        \int_\Omega\nu\varphi\D\Omega = (-1)^{\abs{\alpha}}\int_\Omega fD^\alpha\varphi \D\Omega,
    \end{equation}
    where 
    \begin{equation}
        D^\alpha\varphi=\frac{\partial^{\abs{\alpha}}\varphi}{\partial x_1^{\alpha_1}\dotsb\partial x_n^{\alpha_n}}.
    \end{equation}
\end{defn}
\begin{rem}
    This definition is motivated by the integration by parts method. One wants to find functions that obey integration by parts but are not necessarily differentiable in the classical sense. However, if $f$ is differentiable then the weak and classic derivatives match. It is also important to note that the weak derivative of a function, if it exists, is unique if we identify functions, which only differ on sets of zero measure.
\end{rem}
\begin{defn}
    We denote by $W^{m,p}(\Omega)$, for $p\in[1,\infty]$ and $m\in\nn_0$, the set of all functions $f\in \mathrm{L}^p(\Omega)$ with weak derivatives in $\mathrm{L}^p(\Omega)$ up to the order $\abs{\alpha}\le m$. These sets are called \textsc{Sobolev} \emph{spaces}. We define $\mathrm{H}^m(\Omega):=W^{m,2}(\Omega)$.
\end{defn}
\begin{sa}
    The \textsc{Sobolev} space $W^{m,p}(\Omega)$ with the norm
    \begin{equation}
        \norm{f}_{W^{m,p}}:=\left(\int_\Omega\sum_{\abs{\alpha}\le m}\abs{D^{\alpha} f(x)}^p\D\Omega\right)^{1/p},
    \end{equation}
    for $p\in[1,\infty)$, and 
    \begin{equation}
        \norm{f}_{W^{m,p}}:=\max_{\abs{\alpha}\le m}\left(\esssup_{x\in\Omega}\abs{D^{\alpha}f(x)}\right)
    \end{equation}
    if $p=\infty$, is a \textsc{Banach} space. $\mathrm{H}^m(\Omega)$ with the inner product
    \begin{equation}
        \dotp{u}{v}_{\mathrm{H}^m}:=\sum_{\abs{\alpha}\le m}\dotp{D^{\alpha}u}{D^{\alpha}v}=\sum_{\abs{\alpha}\le m}\int_\Omega D^\alpha u D^\alpha v\D\Omega \quad \forall u,v\in \mathrm{H}^m(\Omega)
    \end{equation}
    is a \textsc{Hilbert} space.
\end{sa}
\begin{rem}
    The spaces $\mathrm{H}^m$ are very important for many numerical methods because of the property that they are \textsc{Hilbert} spaces. The whole theory, which follows hereafter, relies heavily on this assumption. We will also use $\mathrm{H}_0^m$ to denote the closure of $\mathrm{C}^\infty_0$ with respect to $\norm{\cdot}_{\mathrm{H}^m}$. Further explanation on this process is given in \cite{Jost2013}
\end{rem}

\section{The finite element method}
\label{sec:fem}
This section covers the basics of the finite element method (FEM). We still use \cite{Ganesan2017} as a reference.
Let us start by introducing the concept of \emph{weak solutions}. Consider the \textsc{Poisson} problem
\begin{equation}
\label{eq:poissonclassic}
    -\Delta u = f \quad \text{in }\Omega
\end{equation}
and $u=0$ on the boundary $\partial\Omega$ of $\Omega$, where $u,f\colon \Omega\to\rr$. This formulation requires $u\in \mathrm{C}^2(\Omega)$ if $f\in\mathrm{C}^0(\Omega)$ is prescribed. In other examples this often excludes the physical solution, so we want to reduce the required regularity. For this, we integrate both sides over $\Omega$ and multiply with a test function $\varphi\in \mathrm{C}^\infty_0(\Omega)$ to obtain
\begin{equation}
    -\int_\Omega \Delta u\varphi\D\Omega =\int_\Omega f\varphi\D\Omega,\quad\forall\phi\in\mathrm{C}^\infty_0(\Omega).
\end{equation}
If we now apply \textsc{Green}'s theorem on the left side, we obtain
\begin{equation}
    \int_\Omega \nabla u\cdot\nabla \varphi\D\Omega = \int_\Omega f\varphi\D\Omega \quad\forall\varphi\in \mathrm{C}^\infty_0(\Omega)\label{eq:laplace}.
\end{equation}
We call this equation the \emph{weak formulation} of \eqref{eq:poissonclassic}.
The boundary term has vanished because $\varphi$ is 0 on the boundary as we have stated in Remark \ref{rem:testfzero}.
We can observe that we could use \textsc{Green} here because we assume $u\in \mathrm{C}^2(\Omega)$. But \eqref{eq:laplace} imposes much fewer regularity requirements than the
classical formulation. We only need $u,\varphi\in\mathrm{H}^1(\Omega)$ to satisfy the equation. The space of acceptable solutions is now more extensive than before. Also, every solution of \eqref{eq:poissonclassic} automatically satisfies \eqref{eq:laplace}.

\begin{defn}
    Let $V$ be a \textsc{Hilbert} space. A bilinear form  $a\colon V\times V\to\rr$ is said to be \emph{continuous} if there exists a constant $\beta>0$ such that
    \begin{equation}
        a(u,v)\le\beta\norm{u}\norm{v}\quad \forall u,v\in V,
    \end{equation}
    and \emph{coercive} if 
    \begin{equation}
        \exists\alpha>0\colon \quad a(u,u)\ge \alpha\norm{u}^2\quad\forall u\in V.
    \end{equation}
\end{defn}
\begin{rem}
    We see that if $a$ is the inner product of $V$ and induces the norm, then both properties are satisfied. The first identity is simply the \textsc{Cauchy-Schwarz} inequality and the second is fulfilled since $\langle v,v\rangle=\norm{v}^2$. The term $\sqrt{a(v,v)}$ is called \emph{energy norm}, which is the natural norm for error analysis of this problem.
\end{rem}
\begin{sa}[\textsc{Lax-Milgram}]
    \label{sa:LaxMilgram}
    Let $V$ be a \textsc{Hilbert} space, $a(\cdot,\cdot)$ be a continuous coercive bilinear form and $F$ a continuous linear functional. Then there exists a unique $u\in V$ such that
    \begin{equation}
        a(u,v)=F(v)\quad \forall v\in V.\label{eq:generellinPDE}
    \end{equation}
\end{sa}
\begin{rem}
    Why is this relevant to us? At the first glance it is not obvious what this theorem has to do with numerical approximations. It turns out that any linear partial differential equation (linear PDE) in weak formulation can be written in the form \eqref{eq:generellinPDE}, where $u$ are the unknowns and $v$ is a test function.
\end{rem}
\begin{bsp}
    Let us revisit \eqref{eq:laplace}. We can see that we can rewrite it in terms of $a$ and $F$ by setting 
    \begin{equation}
        a(u,v):=\int_\Omega \nabla u\cdot \nabla v\D\Omega
    \end{equation}
    and $F(v)=\int fv\D\Omega$ for $u,v\in \mathrm{H}^1(\Omega)$. Note, that $a$ is not coercive on $\mathrm{H}^1(\Omega)$. Consider $u\equiv c$ for $c\in\rr$ constant. Then $a(u,u)=0$ but $u$ is not necessarily zero. However, on $\mathrm{H}^1_0(\Omega)$ $a$ is an inner product and, thus, coercive (\textsc{Poincaré} inequality), so we can still deduce that the weak formulation \eqref{eq:laplace} has a unique solution for zero boundary conditions.
\end{bsp}
\subsection{Standard \textsc{Galerkin} method}
 Recall that we require $u\in \mathrm{H}^1_0(\Omega)$ in our example earlier. The problem is that $\mathrm{H}^1(\Omega)$ is a space of infinite dimension. Because no computer can handle infinitely many cases, we have to reduce the problem somehow. Thus we use finite dimensional subspaces of the solution space and calculate the best approximation in this subspace. How these spaces can be constructed, will be explained later on. 
\par 
Let $V$ be a \textsc{Hilbert} space. Furthermore let $V_h\subset V$ be an $n$ dimensional subspace, $n\in\nn$, with a so called discretization parameter $h$.
Our new problem is given by
\begin{equation}
a(u_h,v_h) = F(v_h) \quad \forall v_h\in V_h \label{eq:galerkindiscrete}
\end{equation}
for the discrete solution $u_h\in V_h$. We want that the discrete solution converges to the continuous one, when $h\to 0$. Because the properties of $a$ and $F$ are also fulfilled restricted to $V_h$, the \textsc{Lax-Milgram} theorem still guarantees existence and uniqueness of the solution. 
We will rewrite \eqref{eq:galerkindiscrete} as a linear system of equations. By $\{\varphi_i\}$ for $i=1,\dotsc,n$, we denote a basis of $V_h$. Obviously, there exist coefficients $(U_j)_1^n\subset\rr$ such that
\begin{equation}
    u_h=\sum_{j=1}^{n}U_j\varphi_j,\quad \nabla u_h=\sum_{j=1}^{n}U_j\nabla\varphi_j.
\end{equation}
almost everywhere. The coefficients $U_j$ are also called degrees of freedom or unknowns. Because we can use the basis $\{\varphi_j\}_j$ for the test functions in $V_h$, we can rewrite \eqref{eq:galerkindiscrete} as 
\begin{equation}
    a\left(\sum_{j=1}^{n}U_j\varphi_j(x),\varphi_i\right)= F(\varphi_i)\quad \forall i=1,\dotsc,n.
\end{equation}
If we recall that $a$ is a bilinear form, we can also write
\begin{equation}
    \sum_{j=1}^{n}U_ja(\varphi_j,\varphi_i)=F(\varphi_i) \quad\forall i=1,\dotsc,n.
\end{equation}
This already looks like a matrix-vector multiplication. If we define $a_{i,j}=a(\varphi_j,\varphi_i)$ and $b_i=F(\varphi_i)$, we obtain the linear problem
\begin{equation}
    AU=b,
\end{equation} which can be solved by any solver for linear systems of equations. The matrix $A$ is often called \emph{stiffness matrix} and $b$ the \emph{load vector}.
\begin{rem}
    What happens if the problem is not linear? One can then still derive a weak formulation of the form
    \begin{equation}
        F(u,v) = 0 \quad\forall v \in V\label{eq:nonlinear}
    \end{equation}
    with some nonlinear operator $F:V\times V\to\rr$.
    This problem can also be projected to a finite-dimensional subspace with basis functions of $V_h$ as above. \eqref{eq:nonlinear} can then be rewritten as 
    \begin{equation}
        F(u_h, \varphi_i) = 0 \quad \forall i=1,\dotsc,n,
    \end{equation}
    to obtain a discrete solution $u_h\in V_h$. This would then be plugged into a non-linear solver. However, the existence or even uniqueness of a solution cannot be guaranteed and must often be assessed on a case-by-case basis. This is an open research topic. There exist some approaches to this problem, which can be found in \cite{Girault1986}
\end{rem}
\subsection{Finite element spaces}
\label{subsec:finitelem}
For now, we handled the problem with an arbitrary subspace $V_h$. But how would we choose such space and its basis functions?
\begin{notation}
    Let $K\subset \Omega$. We denote by
    \begin{equation}
        P_k(K):=\left\{p\colon K\to\rr\left\vert p(x)=\sum_{\abs{\alpha}\le k}c_\alpha x^\alpha,\right.\quad x\in K\right\}
    \end{equation}
    the set of all polynomials of degree less than or equal to $k$ and $c_\alpha$ are constant coefficients.
\end{notation}
We will construct a mesh by starting with a decomposition $\mathcal{T}_h$ of $\Omega$ into open cells $K$ with $\overline{\Omega}=\bigcup_{K\in\mathcal{T}_h}\overline{K}$.
\begin{defn}
    $(K,P_k(K),\Sigma_k)$ is called a \emph{finite element}, where $\Sigma_k$ denotes the set of degrees of freedom.
\end{defn}
   Not all $\mathcal{T}_h$ are admissible.
\begin{defn}
    A decomposition of the domain $\Omega\subset\rr^d$ into simplices $K\in\mathcal{T}_h$ is admissible if
    \begin{enumerate}
        \item $\overline{\Omega}=\bigcup_{K\in\tau_h}\overline{K}$,
        \item any nonempty intersection of two cells $\overline{K_1}\cap\overline{K_2}$ is either a vertex, an edge or a face of both cells.
    \end{enumerate}
\end{defn}
The following theorem ensures that the combination of all cells still results in $V_h$ being a subset of $\mathrm{H}^1(\Omega)$.
\begin{sa}
    If for every $K\in\mathcal{T}_h,P_k(K)\subset \mathrm{H}^1(K)$, and $V_h\subset \mathrm{C}^0(\overline\Omega)$, then $V_h\subset \mathrm{H}^1(\Omega)$.
\end{sa}
\begin{rem}
    If we take a look back at the last theorem, we can see that the continuity of the degrees of freedom across neighboring faces is enough for our solution to be in $\mathrm{H}^1(\Omega)$. 
\end{rem}
\begin{proof}[Proof taken from \cite{Ganesan2017}]
    Let $v\in V_h$ be given. If we can show that the weak derivatives $D^\alpha v$ are in $ \mathrm{L}^2(\Omega)$ for $\abs{\alpha}=1$, we showed the theorem. The natural choice would be the piecewise defined function $w_K:=D^\alpha(v\vert_K)\in \mathrm{L}^2(K)$. Let $\varphi\in \mathrm{C}^\infty_0(\Omega)$ be arbitrary. It holds that 
    \begin{equation}
        \int_\Omega(w\varphi+vD^\alpha \varphi)\D x = \sum_{K\in\mathcal{T}_h}\int_K(D^\alpha(v\vert_K)\varphi+v\vert_K D^\alpha\varphi)\D x,
    \end{equation}
    where we just used the linearity of the integral. If we recall the definition of the weak derivative (Definition \ref{defn:weakderivative}), we can see how we can rewrite $D^\alpha(v\vert_k)$. We obtain
    \begin{align}
        \sum_{K\in\tau_h}\int_K(D^\alpha(v\vert_K)\varphi+v\vert_K D^\alpha\varphi)\D x&=\sum_{K\in\tau_h}\left(-\int_K v\vert_KD^\alpha\varphi+\int_K v\vert_K D^\alpha\varphi +\int_{\partial K}v\vert_K\varphi n_K\D\partial K\right),\\\intertext{which is obviously just}& =\sum_{K\in\tau_h}\int_{\partial K}v\vert_K\varphi n_K\D\partial K,
    \end{align}
    where $n_k$ is the outer unit normal for $K$. We just applied integration by parts to the first term. Because we chose $\varphi$ to be zero on the boundary of $\Omega$, the integral over each boundary face of $\Omega$ becomes zero. For all inner faces $\partial K_1\cap \partial K_2$ we get the term twice, once for every cell. However both times the normal points in the opposite direction. So our equation reduces to 
    \begin{equation}
        \sum_{K\in\tau_h}\int_{\partial K}v\vert_K\varphi n_K\D\partial K=0 \quad \forall\varphi\in \mathrm{C}^\infty_0.
    \end{equation}
    That proofs that $w$ is indeed the weak derivative of $v$. Because $v$ was arbitrary, it follows that $V_h\subset \mathrm{H}^1(\Omega)$ and this proofs the theorem.
\end{proof}

Another interesting topic to consider, is the order of convergence. If we choose $\dim P_k$ equally on all cells, one can expect a convergence of order $k+1$. However, in practice this is influenced by the time stepping scheme if the problem is time dependent. If the geometry is not rectangular, the mesh approximation to the geometry will also influence the order of convergence. To measure the order of convergence empirically, one defines the $EOC$
\begin{defn}
    For a set of errors $\varepsilon_k$ and discretization $h_k$, where $h\to 0$ for $k\to\infty$, we define the \emph{experimental order of convergence (EOC)} as the limit of 
    \begin{equation}
        EOC_k(\varepsilon_k,h_k)=-\frac{\log\frac{\varepsilon_k}{\varepsilon_{k-1}}}{\log{\frac{h_k}{h_{k-1}}}}.\label{eq:EOC},
    \end{equation} 
    as $k\to\infty$, where $h_k\to 0$ as $k\to\infty$.
\end{defn}
\begin{rem}
    In practice, it is not possible to compute a real limit. Usually, one calculates four or five refinements.
\end{rem}
This short discussion of the finite element method does not claim to be comprehensive, but rather a short overview of important facts, which are necessary to interpret the numerical results presented later.  
\section{\textsc{Laplace} transform}
\label{sec:laplacetransform}
In this section we will introduce the \textsc{Laplace} transform and some of its basic properties. We will loosely follow \cite{Widder1945} for this.
\begin{defn}
    For a function $f\colon\Omega\times\rr^+_0\to\rr$, we call
    \begin{equation}
        L_f(x,s):=\mathcal{L}\{f\}(s):=\int_0^\infty f(x,t)e^{-st}\D t\label{eq:laplacetrafo}
    \end{equation}
    the \emph{\textsc{Laplace} transform} of $f$, where $s\in\cc$ is the so-called frequency parameter. 
\end{defn}
Typically $t$ will be the time variable. In this case this is a transformation of $f$ from the time domain to the frequency domain. Of course this definition only makes sense if \eqref{eq:laplacetrafo} converges for some $s$. From complex analysis we know that if it converges for some $s_c=a_c+ib_c$, it converges in $A_c:=\{s\in\cc\colon a>a_c\}$. Note, that $a_c$ may be $\pm\infty$.
\begin{defn}
    If $a_c$ is minimal such that the integral diverges in $A_d:=\{s\in\cc\colon a<a_c\}$ we call $a_c$ the \emph{abscissa of convergence}. 
\end{defn}
\begin{rem}
    If we replace the lower limit of the integral in \eqref{eq:laplacetrafo} with $-\infty$, we get the \emph{bilateral \textsc{Laplace} transform}.
\end{rem}
\begin{bsp}
    An important example for a bilateral \textsc{Laplace} transform is the well-known Gamma function
    \begin{equation}
        \Gamma(s)=\int_0^\infty x^{s-1}e^{-x}\D x=\int_{-\infty}^\infty e^{-st}e^{-e^{-t}}\D t.
    \end{equation}
    This transformation is obtained by setting $x:=e^{-t}$, which is valid because $x$ should be positive. The substitution for differentials has been considered. 
\end{bsp}
We can give a relationship between the \textsc{Laplace} and \textsc{Fourier} transforms.

\begin{rem}
    Consider a bilateral \textsc{Laplace} transform with $s:=ib$. We then get
    \begin{equation}
        g(x,b)=L_f(x,ib)=\int_{-\infty}^\infty e^{-ibt}f(x,t)\D t,
    \end{equation}
    which is essentially the \textsc{Fourier} transform of $f$ into $g$.
\end{rem}
\begin{sa}
    If $L_f(x,s) $ is the \textsc{Laplace} transform as defined, we can compute $f$ via the inverse transform
    \begin{equation}
        f(x,t) = \frac{1}{2\pi i}\oint_{\gamma-i\infty}^{\gamma +i\infty}L_f(x,s)e^{st}\D s,
    \end{equation}
    where $\gamma$ is a real number such that the path of integration is inside the convergence domain of the \textsc{Laplace} transform.
\end{sa}
In this chapter, we gathered all the important general mathematical background information, which we will use heavily from now on. 
\chapter{Modeling}
\label{ch:model}
Up to now, our work was in no way specific to the problem that we want to solve. In this chapter, we will be more specific. For this, we will give a (short) introduction into the macroscopic modeling of  non-\textsc{Newtonian} fluids. The introduction for this will, however, be intentionally vague as this work is more focused on mathematical than the physical aspects. After that, we will employ some assumptions to make the problem accessible for a master's thesis.
\section{\textsc{Navier-Stokes} Equation}
Many books have been written about the \textsc{Navier-Stokes} equations. We will use some ideas from \cite{Lukaszewicz2016} and \cite{White2006} to outline the main facts. Just the incompressible variant of the equations will be considered and the density is normalized to one and therefore will be omitted.
\subsection{Basics of fluid dynamics}
To understand fluid dynamics one must consider two coordinate systems. At first, there is the usual fixed \textsc{Eulerian} coordinate system (spatial coordinates) that is stationary. Secondly, there is the \textsc{Lagrangian} coordinate system (material coordinates) that follows one particle in the flow. 
We use $u$ for the velocity, $p$ for the pressure with their normal physical interpretations.
\begin{defn}[material derivative]
    If we want to take the derivative of a quantity $f(x,t)$ in the fluid flow direction we get the \emph{material derivative}, which is given by 
    \begin{equation}
        \frac{D}{Dt}f(x,t):=\frac{\partial f}{\partial t} + u\cdot\nabla f.
    \end{equation}
\end{defn}
\begin{rem}
    Note that instead of $u$ one could choose any vector $x$ to obtain a derivative in the direction of $x$.
\end{rem}
The main idea behind the \textsc{Navier-Stokes} equation is the concept of \emph{conservation}. 
\begin{defn}
    If for a property $P$, it holds that on an arbitrary finite volume $\Omega$
    \begin{equation}
        \frac{d}{dt}\int_\Omega P\D\Omega = -\int_{\partial\Omega}Pu\cdot n\D\partial\Omega+\int_\Omega s\D\Omega,\label{eq:conservation}
    \end{equation}
   with $s$ some source or sink and $n$ the unit normal (outward), is valid, then $P$ is \emph{conserved}.
\end{defn}
\begin{rem}
    Conservation means that over time a property can only change over the boundary or through sources or sinks inside. This is motivated from the mass, energy and momentum conservation in physics.
\end{rem}
\subsection{Momentum equation}
Because we assumed that the density of the fluid is one, the momentum is simply the velocity. The momentum is a conserved property so it holds that
\begin{equation}
    \frac{d}{dt}\int_\Omega u\D\Omega = -\int_{\partial\Omega}uu^Tn\D\partial\Omega +\int_\Omega s\D\Omega,
\end{equation} where we get a rank two tensor in the boundary term because we write $uu^T$ as the dyadic product of the two vectors. Using \textsc{Gauß}'s theorem, we can rewrite the boundary integral. This leads to 
\begin{equation}
    \frac{d}{dt}\int_\Omega u\D\Omega = -\int_\Omega \nabla\cdot(uu^T)\D\Omega +\int_\Omega s\D\Omega.
\end{equation}

\begin{sa}[\textsc{Reynolds} transport theorem]
    Let $f$ be a vector valued function, $u_e$ be the velocity of $\D\Omega$. It holds that
    \begin{equation}
        \frac{d}{dt}\int_{\Omega(t)}f\D \Omega =\int_{\Omega(t)}\partial_t f\D \Omega+\int_{\partial\Omega(t)}(u_e\cdot n)f\D \partial \Omega,
    \end{equation}
    where $n$ is the outward unit normal vector.
\end{sa}
Using the previous theorem and realizing that $\Omega$ is constant in time, we get
\begin{equation}\label{eq:nswithint}
    \int_\Omega \partial_t u +\nabla\cdot(uu^T)-s\D\Omega =0.
\end{equation}
\begin{sa}
    Let $f$ and $g$ be functions $f,g\colon\Omega\subset\rr^n\to\rr^n$. It holds that
    \begin{equation}
    \nabla\cdot(fg^T)=(\nabla\cdot x)y+x\cdot\nabla y.
    \end{equation}
\end{sa}
As \eqref{eq:nswithint} holds for every $\Omega$ the integrand has to be zero (Fundamental lemma of calculus of variations). This realization and the previous theorem lead to 
\begin{equation}
    \partial_t u +u\cdot\nabla u+u\nabla\cdot u - s = 0.
\end{equation}

But because we have mass conservation and incompressibility, it holds that $\nabla\cdot u =0$ (in general $\partial_t \rho + \nabla\cdot(\rho u) =0$). Therefore, our equation reduces to 
\begin{equation}
    \partial_t u+ u\cdot \nabla u -s =0
\end{equation}
This is, apart from $s$, just the material derivative of $u$.
The only unknown remaining is $s$. To compute $s$, we refer to \textsc{Cauchy}'s momentum equation. But first, we have to realize that one can split up $s$ into so-called body forces and surface forces. Hence, 
\begin{equation}
   \partial_t u + u\cdot \nabla u = f_{\mathrm{body}} +f_{\mathrm{surf}} .
\end{equation}
The body forces can be of various types so we will collect all of them in a function $f$. In the \textsc{Cauchy} momentum equation the surface forces are modeled using a  so-called symmetric stress tensor $\tau$, such that
\begin{equation}
    \partial_t u + u\cdot \nabla u = f + \nabla\cdot\tau.
\end{equation}
It is interesting to note that the entries on the diagonal of $\tau$ are the stresses normal to the fluid direction, and all others are parallel to the fluids direction. This motivates to set
\begin{equation}
    \tau = -pI+\sigma,
\end{equation}
where $p$ is the pressure and $I$ the corresponding identity matrix. Plugging this into our equation yields
\begin{equation}
    \partial_t u + u\cdot \nabla u = -\nabla p + f + \nabla\cdot\sigma.
\end{equation}
Note that this equation is not complete. One has to give a model for the so-called stress tensor $\sigma$ and for the pressure $p$. This however, is very fluid dependent. The next section will deal with the derivation of such models for $\sigma,p$ for non-\textsc{Newtonian} fluids.
\section{Non-\textsc{Newtonian} fluids}
\label{sec:physics}

Before we start discussing the two related models used to model the stress tensor, we will give a short introduction into non-\textsc{Newtonian} fluids. A general introduction can be found in \cite{Ouellette2013}.
\subsection{What is a non-\textsc{Newtonian} fluid and why is it relevant?}
Generally speaking, a non-\textsc{Newtonian} fluid differs from a \textsc{Newtonian} fluid in the behavior of the viscosity. \textsc{Newton} formulated several laws, which an ideal fluid should obey. One of them was that the viscosity should be independent of the stress that the fluid encounters. All fluids, which obey this law, are called \textsc{Newtonian} fluids and the others are called non-\textsc{Newtonian}. Non-\textsc{Newtonian} fluids are far more spread as one would imagine: from ketchup to honey and toothpaste to the famous water-cornstarch mixture that jumps on loudspeakers; these types of fluids are everywhere. Even granular movement in space and liquid plastic in 3D printers behaves that way. So there are plenty of reasons to care about the difficult task of modeling these fluids. \par 
There are many different types of non-\textsc{Newtonian} behavior. Ketchup for example has a so called \emph{pseudoplastic} behavior, that means that the viscosity decreases with increased stress. In this work we will cover the fluids that have the so-called \emph{viscoelastic} behavior. That means that elastic and viscous effects are working together as a linear combination. Liquid plastic and granular flows often show this type of non-\textsc{Newtonian} behavior.
\subsection{\textsc{Maxwell} and \textsc{Oldroyd-B} models}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{Maxwell_diagram.pdf}
    \caption{Illustration of the Maxwell model (from \cite{Pekaje})}
    \label{fig:maxwell}
\end{figure}
The \textsc{Maxwell} model is one of the easiest models used to describe such viscoelastic fluids. It is obtained by combining dampers and springs and model them with known physical laws. The easiest case is shown in Figure \ref{fig:maxwell}. The damper accounts for the viscous  and the spring for the elastic part of the fluid's behavior. For more information see \cite{Owens2002} The \textsc{Maxwell} model states that
\begin{equation}
    \frac{\lambda}{\mu_p}\partial_t\sigma +\frac{1}{\mu_p}\sigma = \partial_t \bfB,
\end{equation}
where $\mu_p\in\rr$ is the polymer viscosity, $\lambda$ the so called relaxation time and $\bfB$ the strain or \textsc{Finger} tensor. If we solve this ordinary differential equation for $\sigma$, we obtain
\begin{equation}
    \sigma(t)=\int_{-\infty}^{t}-\mu_p\exp\left(-\frac{t-t'}{\lambda}\right)\partial_{t'} \bfB(t,t')\D t'.
\end{equation}
We now deduced a model for $\sigma$. However, it is unclear how $\bfB$ should be calculated.
\textsc{Oldroyd} proposed to use the so called upper-convected time derivative $\overset{\nabla}{\bfB}$ to obtain an ordinary differential equation for $\bfB$. This leads to the governing equation
\begin{equation}
    \overset{\nabla}{\bfB}:=\partial_t \bfB  + (\bfu\cdot \nabla)\bfB-(\nabla \bfu)\bfB-\bfB(\nabla\bfu)^T=0,
\end{equation}
where $\bfu$ denotes the velocity field. The difference between the upper-convected \textsc{Maxwell} model (UCM) and the \textsc{Oldroyd-B} model (both introduced by James G. \textsc{Oldroyd}) lies in the solvent viscosity. The UCM model calculates the flow using the \textsc{Euler's} equations and the \textsc{Oldroyd-B} model uses the \textsc{Navier-Stokes} equations. Note, that one can extend the formula for $\sigma$ by allowing
\begin{equation}
    \sigma(t)=\int_{-\infty}^{t}-\partial_{t'}\bfB(t,t')G(t,t')\D t',
\end{equation}
where $G$ is the so called \emph{relaxation modulus}. This opens the possibility for more advanced models. The whole integral for $\sigma$ can be interpreted as a history dependency. Every past timestep affects the current one. The relaxation modulus can be seen as a weight function in this context. We want that the more a past timestep lies in the past the less relevant it is for the current calculation.
\section{Dimensional reduction}
After we have discussed the physical aspects in the previous sections, we will now focus on making these equations easier to handle. To provide better readability we will omit the arguments of the arising functions, where it is obvious. We start from the well-known \textsc{Navier-Stokes} equations
\begin{align}
\label{eq:NS3Dbegin}
    \frac{\partial \bfu}{\partial t}+(\bfu\cdot \nabla)\bfu &= \bff +\nabla\cdot\sigma +\mu_s\Delta\bfu-\nabla p,\\
    \ddiv(\bfu)&= 0,\label{eq:div0}\\
    \bfu &= \bfu_b \text{ on }\partial\hat\Omega,\\
    \bfu(t=0) &=\bfu_0,
\end{align}
where $t\in[0,T]$ is the current time and $T$ the end time of our simulation. We set a domain $\hat\Omega\subset\rr^3$ and an element $\hat\bfx\in\hat\Omega$. We also have $\bfu(t,\hat\bfx)\colon \rr^+\times\hat\Omega\to\rr^3$ as the velocity vector, $\bff(t,\hat\bfx)\colon\rr^+\times\hat\Omega\to\rr^3$ a generic source or sink term and $\sigma(t,\hat\bfx)\colon\rr^+\times\hat\Omega\to\rr^{3\times 3}$ the stress tensor. As usual $\mu_s\in\rr^+$ denotes the solvent viscosity. We will use $p(t,\hat\bfx)\colon\rr^+\times\hat\Omega\to\rr$ as the pressure. Our boundary condition for $\bfu$ is denoted by $\bfu_b$.
The difference between \textsc{Newtonian} and non-\textsc{Newtonian} fluids lies in the definition of $\sigma$. In the UCM or \textsc{Oldroyd-B} model the stress tensor is given by (see \ref{sec:physics}):
\begin{equation}
    \sigma(t,\hat\bfx) = \int_{-\infty}^t-\partial_{t'}\bfB(t,t',\hat\bfx)G(t,t')\D t',
    \label{eq:generalsig}
\end{equation}
where $G\colon\rr^+\times\rr^+\to\rr$ is a weight function which decays fast in $t'$. In both physical models, which we have discussed in section \ref{sec:physics}, $G$ is given by:
\begin{equation}
    G(t,t')=\mu_p\cdot e^{-(t-t')/\lambda},
    \label{eq:G}
\end{equation} 
where $\mu_p\in\rr^+$ is the polymer viscosity and $\lambda\in\rr$ the relaxation time. Both are fluid- dependent parameters. However, $G$ can be more complex. For example, if $G$ becomes space-dependent, this introduces many new problems. This is why we will stick to \eqref{eq:G} for now.
\par 
The term $\bfB\colon\rr^+\times\rr^+\times\hat\Omega\to\rr^{3\times 3}$ in \eqref{eq:generalsig} is called the \emph{\textsc{Finger} tensor} and obeys the differential equation
\begin{equation}
\label{eq:Bfull}
    \partial_t \bfB + (\bfu\cdot\nabla)\bfB-(\nabla \bfu)\bfB-\bfB(\nabla\bfu)^T = \bm{0}.
\end{equation}
We introduce the initial and boundary conditions
\begin{align}
    \bfB(t',t', \hat\bfx) &\equiv\bm{1},\\
    \bfB(0,t',\hat\bfx) &\equiv\bm{1},
\end{align}
where the last condition implies the assumption that we start the computation stress free. \par
The variable $t'$, which appears in the last equation, is called \enquote{history variable}. We will discuss its impact later on.
\par 
For now, we will assume that $\bfu, \nabla p $ and $\bff$ are only non-zero in one direction, that is,
\begin{equation}
    \bfu=(0, 0, u)^T,\quad\nabla p= (0,0,\partial_3 p),\quad \bff=(0,0,f),
\end{equation}
where $u,f,p\colon\rr^+\times\hat\Omega\to\rr$.
Because $\ddiv(\bfu)=0$ (see \eqref{eq:div0}), we immediately obtain $\partial_3 u=0$, which leads to
\begin{equation}
    [(\bfu\cdot\nabla)\bfu]_3 = u_1\partial_1 u_3+u_2\partial_2 u_3+u_3\partial_3 u_3 = 0
\end{equation}
and obviously the other components of this term become zero as well. Therefore, we loose the advection term in the \textsc{Navier-Stokes} equations.\\
We will now examine the diffusion term
\begin{equation}
    \Delta \bfu=\begin{pmatrix}
    \Delta u_1\\\Delta u_2\\\Delta u
    \end{pmatrix}=\begin{pmatrix}
    0\\0\\ \partial_1^2u+\partial_2^2u+\partial_3^3u
    \end{pmatrix}=\begin{pmatrix}
    0\\0\\ \partial_1^2u+\partial_2^2 u
    \end{pmatrix}.
\end{equation}
If we take a close look at \eqref{eq:NS3Dbegin}, we can see that in order to fulfill the equations for $u_1$ and $u_2$ ($0=(\nabla\cdot\sigma)_l,\quad l\in\{1,2\}$), the block with indexes $(i,j):i,j\in\{1,2\}$ of $\sigma$ has to be constant in space. The last row and last column are the same because of symmetry of the tensor. We have to make sure that they are constant in the third spatial direction, which is obviously given by our assumptions. 
\par After we treated the \textsc{Navier-Stokes} equations in the last paragraph, we will now focus on the governing equation for the Finger tensor. We already saw that only its last row and last column are of interest for us. Let us look at \eqref{eq:Bfull} in index notation, which reads
\begin{equation}
\label{eq:Bindex}
    \partial_t \bm{B}_{i,j}+\sum_{k=1}^3\bm{u}_k\partial_k \bm{B}_{i,j}-\sum_{k=1}^3\partial_k\bm{u}_i\bm{B}_{k,j}-\sum_{k=1}^3\bm{B}_{i,k}\partial_k\bm{u}_j=0
\end{equation}
We can now put our assumptions for $\bfu$ into it. Additionally, $\partial_3\bfB_{3,j}$ should be $0$. We will just focus on the last row for now. This leads to
\begin{equation}
    \partial_t \bm{B}_{3,j} -\sum_{k=1}^2\partial_ku\bm{B}_{k,j}-\left.\begin{cases}
    0 &, j=1,2\\ \sum_{k=1}^2 \bm{B}_{3,k}\partial_ku &, j=3
    \end{cases}\right\} =0.
\end{equation}
If we revisit \eqref{eq:Bindex}, we observe that
\begin{equation}
     \partial_t \bm{B}_{i,j}=-u(\partial_3 \bm{B}_{i,j})~\forall(i,j)\in\{1,2\}^2
\end{equation}
This shows that if we choose this block constant in the beginning, as required by our assumptions, it will not change over time. In our case we will choose the identity matrix for this. These observations also justify that we only care about the last row and ignore the other ones. If we define $\hat\bfb_j:=\bfB_{3,j}$, we obtain the equation
\begin{equation}
   \partial_t \hat\bfb=\begin{pmatrix}
   \partial_1u\\ \partial_2 u \\ 2\left((\partial_1 u)\bm{b}_1+(\partial_2 u)\bm{b}_2\right)
   \end{pmatrix}.
\end{equation}
We have stated above that $\partial_3\hat\bfb_3=0$ . This directly leads to $\partial_3\sigma_{3,3}=0$. Now, taking a good look at \eqref{eq:NS3Dbegin}, we see that $\sigma_{3,3}$ only contributes with its spatial derivative in $x_3$ direction. So it vanishes from the equations completely. We define
\begin{equation}
\partial_t\bfb=
    \begin{pmatrix}
    \partial_1 u\\\partial_2 u
    \end{pmatrix}.
\end{equation}
Furthermore, we define $\bfs:=\sigma_{3,j}$. Consequentially, we obtain the governing equation
\begin{equation}
    \bfs(t,\hat\bfx) =\int_{-\infty}^t-\partial_{t'}\bfb(t,t',\hat\bfx)G(t,t')\D t'.
\end{equation}
We can now define our new system of equations
\begin{align}
\partial_t u(t,\bfx) &= -\partial_3 p + f +\nabla\cdot \bfs+\mu_s\Delta u,\\
\bfs(t,\bfx) &=\int_{-\infty}^t-\partial_{t'}\bfb(t,t',\bfx)G(t,t')\D t',\label{eq:s2D}\\
\partial_t\bfb(t,t',\bfx)&=
\nabla u,
\end{align}
where $\Omega\subset\rr^2$ is the domain with an element $\bfx$. We let $u(t,\bfx), p(t,\bfx), f(t,\bfx)\colon\rr^+\times\rr^2\to\rr$ denote the third component of the velocity, the pressure and a generic source/sink term respectively. $\Delta$ stands for the two-dimensional \textsc{Laplace}-operator. To define the stress and finger tensor, we use $\bfs(t,\bfx)$ and  $\bfb(t,\bfx)\colon\rr^+\times\rr^2\to\rr^2$ respectively.

By using our assumptions, we now deduced a true two-dimensional problem. This can be interpreted as a slice orthogonally to the fluid's flow direction. During this deduction we silently eliminated the nonlinearity in $\bfb_3$ because it is not relevant for the equations anymore. This makes work much easier, as we will see later on.
\section{Transformation of the equation into the frequency domain}
The next step, that is usually taken, is the introduction of an \enquote{age} variable $\tau=t-t'$. This is sensible because if we take a look at \eqref{eq:s2D}, we see that only the times $t'$ close to $t$ are relevant (recall that $G$ is exponentially declining the larger the difference between $t$ and $t'$). The further back in history $t'$ gets, the less contribution it makes. By putting this transformation into our equations, we obtain
\begin{equation}
    \bfs(t,\bfx)=\int_0^\infty\partial_\tau\bfb(t,t-\tau,\bfx)G(t,t-\tau)\D\tau.\label{eq:sage}
\end{equation}
This integral runs \enquote{backwards} in time. Using the chain rule the governing equation for the Finger tensor transforms to  
\begin{equation}
    \partial_t \bfb +\partial_\tau\bfb = \nabla u,
\end{equation}
with the corresponding boundary and initial conditions
\begin{align}
    \bfb(t,t) &= \bm{0},\\
    \bfb(t,0) &= \bm{0}.
\end{align}
At first glance this appears to have made our situation worse because we now have two time derivatives in the equation. Luckily, there is a tool that can help us with that: the \textsc{Laplace} transformation. This is explained extensively in section \ref{sec:laplacetransform}. We have
\begin{equation}
L_{\bfb}(t,\bfx,s) =\int_0^\infty\bfb(t,t-\tau,\bfx)e^{-s\tau}\D\tau
\end{equation}
as the \textsc{Laplace} transform of $\bfb$, where $s\in\cc$ is the frequency parameter. 
We can switch derivative and integral because we assume both limits to exist.
\begin{equation}
    \partial_tL_{\bfb}(t,\bfx,s) + L_{\partial_\tau\bfb}(t,\bfx,s) = \frac{1}{s}\nabla u.
\end{equation}
However, because $\partial_\tau$ is not independent of $\tau$, we have to use integration by parts to transform it to
\begin{align}
    L_{\partial_\tau\bfb}(t,\bfx,s) &= \int_0^\infty\partial_\tau\bfb(t,t-\tau,\bfx)e^{-s\tau}\D\tau\\ &=\lim_{r\to\infty}\bfb(t,t-r,\bfx)e^{-sr}-\bfb(t,t,\bfx)e^{-s\cdot 0}+s\int_0^\infty\bfb(t,t-\tau)e^{-s\tau}\D\tau.\\
    \intertext{The first term vanishes because the exponential function dominates the behaviour of this term. This is a necessary condition for the \textsc{Laplace} transform to converge.}
    &= -\bfb(t,t,\bfx) +sL_{\bfb}(t,\bfx, s)\\
    &= sL_{\bfb}(t,\bfx,s).
\end{align}
We have successfully eliminated the time derivative in $\tau$ direction. The governing equation for the \textsc{Laplace} transform of the finger tensor is given by
\begin{equation}
(\partial_t +s)L_{\bfb}(t,\bfx,s) = \frac{1}{s}\nabla u
\end{equation}
The corresponding initial condition is 
\begin{equation}
    L_{\bfb}(0,\bfx,s) = \bm{0}.
\end{equation} 
As a next step, we will introduce the conformation tensor, which non-dimensionalizes $L_{\bfb}$ . It is defined as 
\begin{equation}
    \bfC_s(t,\bfx) := sL_{\bfb}(t,\bfx,s),
\end{equation}
and has the governing equation
\begin{equation}
    \partial_t\bfC_s(t,\bfx)+s\bfC_s(t,\bfx) =\nabla u
\end{equation}
This transformation worked very well and eliminated many problems, but the question remains: how do we retrieve $\bfs$?
Let's recall \eqref{eq:sage}.
Because we only have a finite history and start stress free, we can cut the integral off at $t$
\begin{equation}
    \bfs(t,\bfx)=\int_0^t\partial_\tau\bfb(t,t-\tau,\bfx)G(t,t-\tau)\D\tau.\label{eq:sagered}
\end{equation}
If we assume that the \textsc{Laplace} transform of $G$ is well-defined and allow that $G$ is space dependent, we can set
\begin{equation}
    g(\bfx,t,s) =\int_0^\infty G(t,t',\bfx)e^{-st'}\D t'.
\end{equation}
Then $\bfs$ is simply given by an inverse Laplace transform so specifically
\begin{equation}
    \bfs(t,\bfx) =\mathcal{L}^{-1}\{\bfC_s(t,\bfx)g(t,\bfx,s)\}(t,\bfx).
\end{equation}
At first glance one may be tempted to be satisfied with this. However, numerically it is unclear how this would work. One of the nice properties of this approach is that if we choose 
\begin{equation}
    G(t,t-\tau)= \mu_p e^{-\tau/\lambda},\quad s=\frac{1}{\lambda},
\end{equation}
where $\lambda$ is the material specific relaxation time, we can retrieve the \textsc{Maxwell} / \textsc{Oldroyd}-B model 
\begin{align}
    \bfs(t,\bfx)&=\mu_p\int_0^t\partial_\tau\bfb(t,t-\tau,\bfx)e^{-\tau/\lambda}\D\tau,\\
    \intertext{using integration by parts,}
    &=\mu_p\bfb(t,0)e^{-t/\lambda}-\mu_p\bfb(t,t)e^{-0/\lambda}+\frac{\mu_p}{\lambda}\int_0^t\bfb(t,t-\tau)e^{-\tau/\lambda}\D\tau.\\
    \intertext{If we use the boundary and initial conditions and extend the integral to $\infty$ (still equal because for $\tau>t$ $\bfb(t,\tau)=0$), we obtain}
    &=\frac{\mu_p}{\lambda}\int_0^\infty\bfb(t,t-\tau)e^{-\tau/\lambda}\D\tau\\
    &=\frac{\mu_p}{\lambda}L_{\bfb}(t,\bfx,1/\lambda) = \mu_p\bfC_{1/\lambda}.
\end{align}
So using the assumptions on $G$ and $\bfu$, we removed the integral term completely! In this example the stress tensor is just the scaled conformation tensor. 
\chapter{Simulation}
This chapter will deal with all aspects of numerical considerations. At first, we will build the numerical scheme and discuss its convergence properties. After that we will look at some results that could be obtained.
\section{Discretization and building the numerical scheme}
The next step will be to build a numerical scheme. For this, we first need the weak formulation. Then we will discuss the discretizations in space and time. Our equations are given by 
\begin{align}
    \label{eq:transfeq1}
    \partial_t u(t,\bfx) &= -\partial_3 p + f +\nabla\cdot \bfs+\mu_s\Delta u,\\
    \label{eq:transfeq2}
    \bfs(t,\bfx)&=\mu_p\bfC_{1/\lambda},\\
    \partial_t\bfC_{1/\lambda}(t,\bfx) &= -\frac{1}{\lambda}\bfC_{1/\lambda}(t,\bfx)+\nabla u
    \label{eq:transfeq3}
\end{align}
\subsection{Weak formulation}
To obtain the weak formulation for equations \eqref{eq:transfeq1} to \eqref{eq:transfeq3}, we will use the standard approach as discussed in subsection \ref{subsec:finitelem}. So let $\varphi = (\varphi_1,\varphi_2)\in \mathrm{C}^\infty_0(\Omega\times\rr)$ with values in $\rr^2$ and $\psi\in \mathrm{C}^\infty_0(\Omega\times\rr)$ with values in $\rr$ be test functions of compact support. We will later on discuss simulation cases, where the boundary conditions are not 0, but for now we will use this restriction. By integrating in space, we can transform \eqref{eq:transfeq3} to 
\begin{equation}
    \int_\Omega(\partial_t\bfC_{1/\lambda}+\frac{1}{\lambda}\bfC_{1/\lambda})\cdot\varphi\D\Omega = 
   \int_\Omega \nabla u\cdot \varphi\D\Omega.
\end{equation}
We will not modify this equation further, as we do not have any knowledge about the boundary values of $\bfC$. The spatial derivatives of $u$ however, are not a problem during the simulation as $u$ not time-dependent in this equation and therefore known. Equation \eqref{eq:transfeq2} does not need to be handled, so what remains is equation \eqref{eq:transfeq1}, which is also the most complicated one. Integration over $\Omega$ and multiplication with the respective test function yields
\begin{equation}
    \int_\Omega(\partial_t u + \partial_3 p -\nabla\cdot \bfs -\mu_s\Delta u)\psi\D\Omega = 0.
\end{equation}
Using the linearity of the integral, we get
\begin{equation}
    \int_\Omega(\partial_t u)\psi\D\Omega +\int_\Omega\partial_3 p\psi\D\Omega -\int_\Omega(\nabla\cdot \bfs)\psi\D\Omega -\mu_s\int_\Omega\psi\Delta u\D\Omega=0.
\end{equation}
The first two terms do not need additional work. So we will focus on the latter two. The last term can be rewritten using well-known \textsc{Green}'s Theorem. So we obtain
\begin{equation}
    \int_\Omega \psi\Delta u = \int_\Omega\nabla u\cdot \nabla\psi\D\Omega.
\end{equation}
Applying basic calculus and integration by parts enables us to transform the remaining term
\begin{equation}
    \int_\Omega \psi(\nabla\cdot\bfs)\D\Omega =\int_{\partial\Omega}\psi\bfs\D\partial\Omega -\int_\Omega\bfs\cdot\nabla\psi\D\Omega.
\end{equation}
Because we chose $\psi=u = 0$ on $\partial\Omega$, the boundary integral becomes $0$. Inserting both transformations into the original equation, yields
\begin{equation}
    \int_\Omega(\partial_t u)\psi\D\Omega +\int_\Omega\partial_3 p\psi\D\Omega + \int_\Omega\bfs\cdot\nabla\psi\D\Omega+\mu_s\int_\Omega\nabla u\cdot\nabla\psi\D\Omega = 0.
\end{equation}
In summary, we can give the following system of weak formulations for our governing equations
\begin{align}
\label{eq:weaktimecon1}
     \int_\Omega(\partial_t u)\psi\D\Omega +\int_\Omega\partial_3 p\psi\D\Omega + \int_\Omega\bfs\cdot\nabla\psi\D\Omega+\mu_s\int_\Omega\nabla u\cdot\nabla\psi\D\Omega = 0,\\
     \label{eq:weaktimecon2}\bfs =\mu_p\bfC_{1/\lambda},\\
     \label{eq:weaktimecon3}
      \int_\Omega(\partial_t\bfC_{1/\lambda}+\frac{1}{\lambda}\bfC_{1/\lambda})\cdot\varphi\D\Omega = 
     \int_\Omega \nabla u\cdot\varphi\D\Omega.
\end{align}

\subsection{Time discretization}
Our goal in this section is to discretize the time dimension in this equation. To achieve this goal, we will introduce the timesteps
\begin{equation}
    0=t_0,t_1,\dotsc,t_N=T.
\end{equation}
The time derivative will be approximated using the implicit \textsc{Euler} method. To be specific, we approximate 
\begin{equation}
    \partial_t(\cdot)^{n+1}\approx\frac{(\cdot)^{n+1}-(\cdot)^n}{\Delta t},\label{eq:timestep}
\end{equation}
where $n$ refers to the $n$-th timestep, which we assume is already known, and $\Delta t$ is the timestep width. If the argument, on which the differential operator operates, is linear then this results in a linear system to be solved in every timestep. In return for the work we put into every timestep, this method is stable for every timestep width. To learn more about the stability of \textsc{Runge-Kutta} methods in general follow \cite{Hairer1986}.
\par 
For ease of notation we set $(\cdot)^{n+1}:=(\cdot)$. If we put \eqref{eq:timestep} into the weak form \eqref{eq:weaktimecon1}-\eqref{eq:weaktimecon3} at $t=t_{n+1}$, we obtain 
\begin{align}
\label{eq:timedisc1}
  \int_\Omega(u-u^n)\psi\D\Omega +\Delta t\left(\int_\Omega\partial_3 p\psi\D\Omega + \int_\Omega\bfs\cdot\nabla\psi\D\Omega+\mu_s\int_\Omega\nabla u\cdot\nabla\psi\D\Omega\right) = 0,\\
  \label{eq:timedisc2}
  \bfs =\mu_p\bfC_{1/\lambda},\\
  \label{eq:timedisc3}
  \int_\Omega(\bfC_{1/\lambda} - \bfC_{1/\lambda}^n +\frac{\Delta t}{\lambda}\bfC_{1/\lambda})\cdot\varphi\D\Omega = 
  \Delta t\int_\Omega\nabla u\cdot\varphi\D\Omega.
\end{align}
\par 
There are numerous possible means to solve the resulting linear system. 
\subsection{Spatial discretization}
Now that we have transformed the equation in their weak forms, the next thing to consider is the spatial discretization. We will use the finite element method (FEM) for that. We will write the equations in the form $AU=b$. This is not necessary for solving it using our software framework FEniCS (more on FEniCS later on) but for understanding the problem it is nonetheless relevant. 
\par 
At first we have to break the problem down into the bilinear form $a(U,\phi)$ and the linear form $F_{n+1}(\phi)$. We will define $U,\phi\colon\rr^2\to\rr^3$ as
\begin{equation}
   U=\begin{pmatrix}
   \bfC_{1/\lambda}\\u
   \end{pmatrix} \text{ and } 
   \phi=\begin{pmatrix}
   \varphi\\\psi
   \end{pmatrix}.
\end{equation}
Note that these vectors have three entries each. Because we choose the components of $\varphi$   and $\psi$ linear independent, we can write the whole system as a sum of \eqref{eq:timedisc1}-\eqref{eq:timedisc3}. Specifically we obtain 
\begin{align}
\label{eq:sum}
    &\int_\Omega[ u\psi +(1+\frac{\Delta t}{\lambda})\bfC_{1/\lambda}\cdot\varphi - u^n\psi-\bfC_{1/\lambda}^n\cdot\varphi\\\notag&+\Delta t\left(\partial_3 p\psi-\nabla u\cdot\varphi+\mu_p\bfC_{1/\lambda}\cdot\nabla\psi +\mu_s\nabla u\cdot\nabla\psi\right)]\D\Omega =0.
\end{align}
Putting $U$ and $\phi$ into \eqref{eq:sum} results in the equation
\begin{align}
\label{eq:sumcon}
    &\int_\Omega[U\cdot\phi+\Delta t((\mu_pU_{1:2}+\mu_s\nabla U_3)\cdot\nabla\phi_3)+\frac{\Delta t}{\lambda}U_{1:2}\cdot\phi_{1:2}-\Delta t\nabla U_3\cdot\phi_{1:2}]\D\Omega\\\notag
    &=\int_\Omega [U^n\cdot\phi-\Delta t\partial_3 p\phi_3]\D\Omega.
\end{align}
We denoted with 1:2 that the vector containing the first and second entry should be taken. We define $a(U,\phi)$ as the left hand side of the equation. That this is a bilinear form is trivially true due to the linearity of the integral and the dot product. However, it is not symmetric and therefore no inner product. That means, that our resulting matrix $A$ is not symmetric, which will impact the choice of a suited linear solver.\par 
The right hand side of \eqref{eq:sum} is defined as the linear form $F$, which only consists of the term from the time discretization and the derivative of the pressure. We will proof in \ref{sec:existence} that this problem has a unique solution. \par 
We will now discuss, which finite elements should be used. The software FEniCS provides a mesh generator, that uses triangles. We define the ansatz functions $\phi$ as
\begin{equation}
    \phi\in P_1(\Omega)\times P_1(\Omega)\times P_1(\Omega),
\end{equation}
where 
\begin{equation}
    P_1(\Omega):=\{\varphi\in\mathrm{C}^0(\Omega)\colon \varphi|_K\in P_1(K)\quad\forall K\in\mathcal{T}_h\}.
\end{equation}
 In this definition we use $\mathcal{T}_h$ and $P_1(K)$ as defined in subsection \ref{subsec:finitelem}. This is the smallest order a finite element can have to guarantee continuity across the cell boundary. A higher order element is also not necessary because we only use a time integration scheme of order 1. 
\subsection{Existence of a solution}
\label{sec:existence}
We now want to proof, with the help of Theorem \ref{sa:LaxMilgram} (\textsc{Lax-Milgram}), that there exists a unique solution for the problem \eqref{eq:sumcon}. Firstly, we have to discuss the form of the solution space. Because $\bfC_{1/\lambda}$ has no spatial derivatives in the governing equations, we assume $\bfC_{1/\lambda}\in \mathrm{L}^2(\Omega)\times \mathrm{L}^2(\Omega)$. The velocity appears with a spatial derivative of order one, so we want $u\in \mathrm{H}^1_0(\Omega)$. This leads to 
\begin{equation}
    U\in \mathrm{L}^2(\Omega)\times \mathrm{L}^2(\Omega)\times \mathrm{H}^1(\Omega)=:X(\Omega).
\end{equation} The test function $\phi$ should be of the same regularity. We define a norm on this space via the inner product. The product space of \textsc{Hilbert} spaces has an easy inner product
\begin{equation}
    \langle U,\phi\rangle_X = \langle U_1,\phi_1\rangle_{\mathrm{L}^2} +  \langle U_2,\phi_2\rangle_{\mathrm{L}^2} +\langle U_3,\phi_3\rangle_{\mathrm{H}^1},
\end{equation}
where we use the inner products on $\mathrm{L}^2$ and $\mathrm{H}^1$ as defined in section \ref{sec:funcana}. This inner product induces a norm on $X$, which we will use to show the existence of a solution. It is given by
\begin{equation}
    \norm{U}_X^2=\norm{U_{1:2}}_{\mathrm{L}^2}^2+\norm{U_3}_{\mathrm{H}^1}^2
\end{equation}
\begin{sa}
    Let $X=\mathrm{L}^2\times\mathrm{L}^2\times \mathrm{H}^1_0$ be a \textsc{Hilbert} space, $\mu_s\neq 0$ and $\mu_s(\frac{1}{\Delta t}+\frac{1}{\lambda})\g \frac{1}{4}(\mu_p-1)^2$.
    Then the problem in \eqref{eq:sumcon} has unique solution  in $X$.
\end{sa}
\begin{proof}
    We will use theorem \ref{sa:LaxMilgram}(\textsc{Lax-Milgram}) to show this theorem. Therefore we have to show $\abs{a(U,\phi)}\le \beta\norm{U}_X\norm{\phi}_X$ for all $U,\phi\in X$ and for $\beta >0$ (continuity) . Secondly we have to show coercivity so $a(U,U)\ge \alpha\norm{U}^2_X$ for all $U\in X$. \par 
    Let us consider the continuity inequality first. Because $a$ is a bilinear form it is sufficient to show 
    \begin{equation}
        a(U,\phi)\le\beta\norm{U}_X\norm{\phi}_X.
    \end{equation}
    The bilinear form $a$ is given by
    \begin{equation}
        a(U,\phi)=\int U\cdot\phi +\Delta t(\nabla\phi_3(\mu_pU_{1:2}+\mu_s\nabla U_3))+\frac{\Delta t}{\lambda}U_{1:2}\phi_{1:2}-\Delta t\nabla U_3\cdot \phi_{1:2}\D\Omega.
    \end{equation}
    By expanding all terms we obtain
    \begin{equation}
        a(U,\phi)=\int U\cdot\phi +\Delta t\mu_pU_{1:2}\nabla\phi_3+\Delta t\mu_s\nabla \phi_3\cdot\nabla U_3+\frac{\Delta t}{\lambda}U_{1:2}\phi_{1:2}-\Delta t\nabla U_3\cdot\phi_{1:2}\D\Omega.
    \end{equation}
    Using the linearity of the integral and the positivity of a norm, it yields
    \begin{align}
        a(U,\phi)&\le \left(1+\frac{\Delta t}{\lambda}\right)\ltnorm{U_{1:2}}\ltnorm{\phi_{1:2}}+\Delta t\mu_p\ltnorm{U_{1:2}}\ltnorm{\phi_{1:2}}\\&+\Delta t\mu_s\ltnorm{\nabla\phi_3}\ltnorm{\nabla U_3}+\ltnorm{U_3}\ltnorm{\phi_3}+\Delta t\ltnorm{\nabla U_3}\ltnorm{\phi_{1:2}}.
    \end{align}
    To deal with the constant factors, we introduce 
    \begin{equation}
        \beta=2\max\left(1+\frac{\Delta t}{\lambda}, \Delta t\mu_p,\Delta t\mu_s,\Delta t\right).
    \end{equation}
    That way we obtain
    \begin{align}
        a(U,\phi)&\le \frac{\beta}{2}\big(\ltnorm{U_{1:2}}\ltnorm{\phi_{1:2}}+\ltnorm{U_{1:2}}\ltnorm{\nabla\phi_3}+\ltnorm{U_3}\ltnorm{\phi_3}\\&+\ltnorm{\nabla U_3}\ltnorm{\nabla\phi_3}+\ltnorm{\nabla U_3}\ltnorm{\phi_{1:2}}\big).
    \end{align}
    One can observe that the last equation can be interpreted as an inner product of the $\rr^5$. This reinterpretation yields
    \begin{equation}
        a(U,\phi)\le \frac{\beta}{2}\left(\begin{pmatrix}
        \ltnorm{U_{1:2}}\\\ltnorm{U_{1:2}}\\\ltnorm{U_{3}}\\\ltnorm{\nabla U_{3}}\\\ltnorm{\nabla U_{3}}
        \end{pmatrix}\cdot \begin{pmatrix}
        \ltnorm{\phi_{1:2}}\\\ltnorm{\nabla\phi_{3}}\\\ltnorm{\phi_{3}}\\\ltnorm{\nabla \phi_{3}}\\\ltnorm{\phi_{1:2}}
        \end{pmatrix}\right).
    \end{equation}
    Using \textsc{Cauchy-Schwarz} (theorem \ref{sa:Schwarz}) we obtain
    \begin{equation}
        a(U,\phi)\le\frac{\beta}{2}\bigg(2\ltnorm{U_{1:2}}^2+\ltnorm{U_3}^2+2\ltnorm{\nabla U_3}^2
        \bigg)^{1/2}\bigg(2\ltnorm{\phi_{1:2}}^2+\ltnorm{\phi_3}^2+2\ltnorm{\nabla \phi_3}^2\bigg)^{1/2}.
    \end{equation}
    Because the square root is monotonous, we can also write
    \begin{align}
        a(U,\phi)&\le\beta\bigg(\ltnorm{U_{1:2}}^2+\ltnorm{U_3}^2+\ltnorm{\nabla U_3}^2
        \bigg)^{1/2}\bigg(\ltnorm{\phi_{1:2}}^2+\ltnorm{\phi_3}^2+\ltnorm{\nabla \phi_3}^2\bigg)^{1/2}\\&=\beta\norm{U}_X\norm{\phi}_X,
    \end{align}
    which is exactly the continuity constraint. 
    \par The next thing to show is the coercivity. At the beginning will use \textsc{Young's} inequality \cite{Young1912}
    \begin{equation}
        a\cdot b\le\norm{a}\norm{b}\le\frac{\gamma}{2}\norm{a}^2+\frac{1}{2\gamma}\norm{b}^2,
    \end{equation} where $a,b$ are in some normed space and $\gamma\in\rr^+$.
    Using the \textsc{Cauchy-Schwarz} inequality and taking care regarding the sign of $\mu_p-1$ yields
    \begin{equation}
        \Delta t(\mu_p-1)U_{1:2}\cdot \nabla U_3\ge -\Delta t\abs{\mu_p -1}\ltnorm{U_{1:2}}\ltnorm{\nabla U_3}.
    \end{equation}
    We can now use the above mentioned \textsc{Young's} inequality to obtain
    \begin{equation}
        \Delta t(\mu_p-1)U_{1:2}\cdot \nabla U_3\ge -\Delta t\abs{\mu_p-1}\big(\frac{\gamma}{2}\ltnorm{U_{1:2}}^2+\frac{1}{2\gamma}\ltnorm{\nabla U_3}^2\big),
    \end{equation}with some $\gamma\in\rr^+$. Plugging this inequality into the formula for $a$ results in
    \begin{align}
        a(U,U)&\ge \left(1+\frac{\Delta t}{\lambda}\right)\ltnorm{U_{1:2}}^2+\ltnorm{U_3}^2+\Delta t\mu_s\ltnorm{\nabla U_3}^2\\&-\Delta t\abs{\mu_p-1}\left(\frac{\gamma}{2}\ltnorm{U_{1:2}}+\frac{1}{2\gamma}\ltnorm{\nabla U_3}^2\right).
    \end{align}
    If collect the terms with same factors we obtain
    \begin{equation}
        a(U,U)\ge \left(1+\frac{\Delta t}{\lambda}-\Delta t\abs{\mu_p-1}\frac{\gamma}{2}\right)\ltnorm{U_{1:2}}^2+\ltnorm{U_3}^2+\left(\Delta t\mu_s-\frac{\Delta t\abs{\mu_p -1}}{2\gamma}\right)\ltnorm{\nabla U_3}^2.
    \end{equation}
    We want to choose $\gamma$ such that 
    \begin{equation}
        1+\frac{\Delta t}{\lambda}-\Delta t\abs{\mu_p-1}\frac{\gamma}{2}>0 \quad\text{and}\quad\Delta t\mu_s-\frac{\Delta t\abs{\mu_p -1}}{2\gamma}>0.
    \end{equation}
    It is also possible to express the conditions on $\gamma$ as
    \begin{equation}
        \frac{\abs{\mu_p-1} }{2\mu_s}<\gamma<2\frac{1+\frac{\Delta t}{\lambda}}{\Delta t\abs{\mu_p -1}}.
    \end{equation}
    To know if such a $\gamma$ exists we check if
    \begin{equation}
       \frac{\abs{\mu_p-1} }{2\mu_s}<2\frac{1+\frac{\Delta t}{\lambda}}{\Delta t\abs{\mu_p -1}}
    \end{equation}
    holds. This can also be written as
    \begin{equation}
        \mu_s\left(\frac{1}{\Delta t}+\frac{1}{\lambda}\right)>\frac{1}{4}(\mu_p-1)^2.
    \end{equation}
    But this is exactly one of the requirements of the theorem. We can define 
    \begin{equation}
        \alpha:=\min(1+\frac{\Delta t}{\lambda}-\Delta t\abs{\mu_p-1}\frac{\gamma}{2},1,\Delta t\mu_s-\frac{\Delta t\abs{\mu_p -1}}{2\gamma}).
    \end{equation}
    Using the new variable yields
    \begin{equation}
        a(U,U)\ge \alpha(\ltnorm{U}^2+\ltnorm{\nabla U_3}^2)=\alpha\norm{U}_X.
    \end{equation}
    Continuity and coercitivity implies the statement of the theorem as mentioned at the beginning of the proof.
\end{proof}
The condition 
\begin{equation}
\mu_s\left(\frac{1}{\Delta t}+\frac{1}{\lambda}\right)>\frac{1}{4}(\mu_p-1)^2.
\end{equation} needs some discussion. Does it not impose a strong restriction? Consider a given set of $\lambda,\mu_s$ and $\mu_p$. We can always find a $\Delta t$ small enough that the inequality holds. To put it in terms of numerics, we find that we can only guarantee the existence and uniqueness of the solution if the time step size is small enough. Such a constraint reminds one of the \textsc{CFL} condition for Finite Volume schemes. More information on the CFL condition can be found in the original German paper \cite{Courant1928}.
\section{Numerical results}
Now we have everything we need to put our equations into a simulation. We will first introduce the framework, which we use to handle most of the calculations performed for this work. After that we will perform an empirical convergence study and discuss some test cases and limitations of this approach.
\subsection{Software}
Most of the simulations conducted for this work used the FEniCS framework (\cite{AlnaesBlechta2015a}, \cite{LoggMardalEtAl2012a}). Other components of this project are the C++ backend DOLFIN (\cite{LoggWells2010a}, \cite{LoggWellsEtAl2012a}), the compiler for the variational form FFC (\cite{KirbyLogg2006a}, \cite{LoggOlgaardEtAl2012a}, \cite{OlgaardWells2010b}), the language definition for variational forms UFL(\cite{AlnaesEtAl2012}, \cite{Alnaes2012a}) and the corresponding code generator UFC (\cite{AlnaesLoggEtAl2009a}, \cite{AlnaesLoggEtAl2012a}).
\par 
The advantages of using a framework at all are obvious. The less time one spends coding, the more one can assign to theoretical tasks. Another nice property is that the whole debugging process is shortened by a large bit. The software is also throughly tested so bugs are much less frequent. The responsibility of the user is to implement all properties of the finite element approach, one wants to use. This includes the finite element spaces, the weak formulation and the time discretization. Literature on how to get started with FEniCS is easy to find. A nice tutorial is given by the founders of FEniCS in  \cite{Langtangen2017a}. The code, that has been written for this work, can be found on the CD, which accompanies this. 
\subsection{Simulation cases}
The next sections will deal with simulations and their results. This subsection should give a quick overview of all the relevant cases studied. \\
Two domains were used throughout the simulations. 
\begin{figure}
    \includegraphics[width=\textwidth]{meshcircle}
    \caption{Finest mesh of the unit disc}
    \label{fig:mesh}
\end{figure}
\begin{figure}
    \includegraphics[width=\textwidth]{meshsquare}
    \caption{Mesh of a square with sidelength 2}
    \label{fig:meshsquare}
\end{figure}
They can be seen in figures \ref{fig:mesh} and \ref{fig:meshsquare}. The boundary of the unit disc is approximated using a polygonal chain. It is interesting to observe that even for the square the mesh generator returns an unstructured mesh.
We used the unit disc for the following simulation cases:
\begin{itemize}
    \item Convergence of our implementation
    \item Startup flow (fluid at rest in the beginning but perpendicular pressure)
\end{itemize}
The square had applications in these cases:
\begin{itemize}
    \item Startup flow
    \item \enquote{ideal} rheometer cross-section
\end{itemize}
The reason why we simulated the startup flow case twice will be obvious once we compare the results. Videos of these testcases will be available on the CD that accompanies this work.
\subsection{Convergence}
In this section we will use a setup study convergence of the implementation and the order of convergence. We will use the unit disc as a domain that is
\begin{equation}
    \Omega =\{x\in\rr^2|\abs{x}\le 1\}.
\end{equation} 
As a boundary condition, we require
\begin{equation}
u = 0\quad\forall\bfx\in\partial\Omega.
\end{equation}
We want study convergence for the \textsc{Maxwell} model $(\mu_s=0)$, because it is more challenging due to the missing dissipation term.
We set the initial conditions
\begin{equation}
u(t=0) = e^{-\norm{x}_2-1}-1,
\quad\bfC(t=0) = -2\bfx(e^{-(\norm{x}_2^2 -1)}-1)
\end{equation}
where $\bfx\in\Omega$. This initial condition is obviously continuous at the boundary. Because the exact solution of this equation is not known, we will use the concept of \emph{manufactured solution}. The first step in the process of creating a manufactured solution is to set a function, that we want the exact solution to be. For simplicity, we want that the solution stays constant in time.  We could have introduced a time dependent solution here, but it only makes calculations more complex. Next, we plug the solution functions into our equations and add a residual $\bfR\colon\Omega\to\rr^3$ on the right side. It does not matter if we use the classic or weak formulation of our problem. By using the classic formulation we obtain
\begin{align}
0 &= -\partial_3 p-2\mu_p \nabla\cdot [\bfx(e^{-(\norm{x}_2^2 -1)}-1)] +\bfR_1,\\
-\frac{2}{\lambda}\bfx(e^{-(\norm{x}_2^2 -1)}-1)&= \nabla (e^{-(\norm{x}_2^2 -1)}-1) +\bfR_{2:3}.
\end{align}
Note that the time derivatives evaluates to zero in both cases. Next, we solve this set of equations for $\bfR$. To do that we expand the divergence and the gradient operators to obtain
\begin{align}
\bfR_1 &= \partial_3 p +4\mu_p(e^{-(\norm{x}_2^2 -1)}(1-\norm{x}_2^2)-1),\\
\bfR_{2:3} &=2\bfx\left(e^{-(\norm{x}_2^2 -1)}\left(1-\frac{1}{\lambda}\right)+\frac{1}{\lambda}\right).
\end{align}
To solve the equations, we have to add the residual to the weak formulation. This results in 
\begin{align}
\int_\Omega(u-u^n)\psi\D\Omega +\Delta t\left(\int_\Omega\partial_3 p\psi\D\Omega + \int_\Omega\bfs\cdot\nabla\psi\D\Omega-\int_\Omega \bfR_1\psi\D\Omega\right) = 0,\\
\bfs =\mu_p\bfC_{1/\lambda},\\
\int_\Omega(\bfC_{1/\lambda} - \bfC_{1/\lambda}^n +\frac{\Delta t}{\lambda}\bfC_{1/\lambda})\cdot\varphi\D\Omega = 
\Delta t\int_\Omega \nabla u\cdot\varphi\D\Omega+\Delta t\int_{\Omega}\bfR_{2:3}\cdot\varphi\D\Omega.
\end{align}
The solution of this system is exactly our initial condition. This way we can easily calculate approximation errors. 
\begin{table}
    \centering
    \begin{tabular}{c|c|c|c|c}
        $\approx$ \# Elements per diameter& $\mathrm{L}^2$-error&EOC in $\mathrm{L}^2$&$\mathrm{L}^\infty$-error &EOC in $\mathrm{L}^\infty$\\
        \hline
        20 & 0.0797652 & - & 0.877305 & -\\
        40 & 0.0233543 & 1.77207 & 0.195846 & 2.16336\\
        80 & 0.00615334 & 1.92425 & 0.100548 & 0.96184\\
        160 & 0.00163421 & 1.91278 & 0.0369229 & 1.44529\\
        320 & 0.000433982 & 1.91288 & 0.0198643 & 0.89434
    \end{tabular}
    \caption{Convergence of the \textsc{Maxwell} model}
    \label{tab:maxwellconv}
\end{table}

We used $\Delta t = 0.1$ and calculated until $T=1$. As the polymer viscosity we used $1$. Table \ref{tab:maxwellconv} shows the $\mathrm{L}^2$ and $\mathrm{L}^\infty$ error and the experimental order of convergence of both errors. We can observe that the $\mathrm{L}^2$ error is well behaved and results in an EOC, which approaches 2. Unfortunately the error in the $\mathrm{L}^\infty$ does not return something similar. The important thing to note is that the $\mathrm{L}^\infty$ error is monotonously decreasing. It is well-known that it is very difficult to obtain a smooth convergence in $\mathrm{L}^\infty$. It is typical for these kind of simulations that the $\mathrm{L}^\infty$ error is worse than $\mathrm{L}^2$. Also, remember that the boundary of the domain has been approximated by a polygonal chain, which increases proportionally with the number of cells. The order of the geometry approximation influences the order of convergence just like the spatial or time discretization. This might also explain, why in the beginning the EOC is a bit far from the expected 2. As we have 320 elements per diameter we also approximate the circle with 320 segments in the polygonal chain which, to a naked eye, is indistinguishable from a true circle. The time integration order of one is also negatively influencing the EOC. 

\subsection{Startup flow on unit disc}
We will now take a look at a more physically relevant example. Consider a fluid at rest that is subject to a perpendicular pressure gradient. This is basically the setup for the next two simulation cases. However, we will choose different domains and show that this leads to very different results. 
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{UnitDiscSetup}
    \caption{Setup startup flow unit disc}
    \label{fig:unitdiscsetup}
\end{figure}
The setup is shown in figure \ref{fig:unitdiscsetup}. We chose the no slip boundary condition $u=0$ on the boundary of the circle. We assumed a pressure gradient of $\partial_3 p=-5$ and a relaxation time of $\lambda=1$. 
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{UnitDiscCenterline}
    \caption{Centerline velocity with the unit disc domain and $\mu_s=0$, $\mu_p=1$}
    \label{fig:unitdisccenterline}
\end{figure}
Figure \ref{fig:unitdisccenterline} shows the velocity at the centre of the circle. We used the \textsc{Maxwell} model this time with $\mu_p=1$. The typical non-\textsc{Newtonian} oscillations can be seen. We calculated until $T=12$ with $\Delta t=0.001$. The graph for a \textsc{Newtonian} fluid would be monotonously increasing to the steady state velocity.
\subsection{Startup flow on square}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{SquareSetup}
    \caption{Setup of the startup flow simulation on the square domain}
    \label{fig:squaresetup}
\end{figure}
Now we want to repeat this calculation but with a different domain. We will see that this will impact the result. The setup is shown in figure \ref{fig:squaresetup}. A related problem is solved in \cite{A.S.RDuarte2008}. Therefore, we choose periodic boundary conditions on the left and right sides and a no slip boundary condition $u=0$ at the top and bottom.
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{SquareCenterline}
    \caption{Centerline velocity of the start-up flow on the square domain}
    \label{fig:squarecenterline}
\end{figure}
We chose $\partial_3 p=-3$ to obtain the results from \cite{A.S.RDuarte2008}. However, the magnitude of the pressure only affects the amplitude and not the behavior of the fluid. As one can see in figure \ref{fig:squarecenterline} we obtain a very different behavior by changing the domain. This is also a difference to a \textsc{Newtonian} fluid, where we would have gotten the same graph for both domains. Another interesting observation is, that until $t=\lambda$ the behavior of the fluid is monotonous. If we interpret the relaxation time of a \textsc{Newtonian} fluid to be $\infty$ we can explain the absence of maximal and minimal points in their velocity graph. It also seems like every extrema can be found at a multiple of the relaxation time and that these extrema are not differentiable. Shocks, however, can not be found because we solve a linear system of equations where these cannot appear.
\subsection{\enquote{Ideal} rheometer}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{RheometerSetup}
    \caption{Setup for the rheometer simulation case}
    \label{fig:rheometersetup}
\end{figure}
A rheometer is a laboratory device used by rheologists to measure the behaviour of a material to applied forces. It contains a container for the material and a whisk which mixes through it. Properties like viscosity and relaxation times can be studied.
To obtain a two-dimensional problem, this case represents a slice from top to bottom of an infinitively high rheometer.
The setup for this case is shown in figure \ref{fig:rheometersetup}. The left side of the square has the no slip boundary condition $u=0$. The top and bottom side are coupled with a periodic boundary condition. The right side has the \textsc{Dirichlet} boundary condition $u=10$. 
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{RheometerCenterline}
    \caption{Centerline velocity in the rheometer with $\mu_s=0.1$, $\mu_p=0.9$, $\lambda=2$ }
    \label{fig:rheomcenter}
\end{figure} 
\par The centerline velocity of this simulation can be seen in figure \ref{fig:rheomcenter}. We chose the \textsc{Oldroyd}-B model with $\mu_s=0.1$ and $\mu_p=0.9$. Our relaxation time was set to $\lambda=2$ and we calculated until $T=4$ with a step size of $\Delta t=0.001$. Like before one can clearly see that we do not have a fluid that is showing \textsc{Newtonian} behavior. This is the first case, where we have set $\mu_s>0$. This can be clearly observed in figure \ref{fig:rheomcenter} because the resulting graph looks like a differentiable function. This is typical for advective problems with dissipation from a second order derivative term.
\chapter{Different approaches for the integral equation}
In chapter \ref{ch:model} we could eliminate the integral from equation \eqref{eq:generalsig} completely by taking sensible assumptions on the memory function $G$. However, this is a very specific case and the more complex physical models do not satisfy these assumptions. In this chapter we will discuss possibilities for a more general approach. 
\section{Combination of relaxation times}
In physics, most of the time it is sufficient to model the fluid's behavior using a combination of relaxation times. So for $N\in\nn$ we set
\begin{equation}
    G(\tau)=\sum_{n=1}^{N}\mu_p^{(n)}e^{-\tau/\lambda_n},
\end{equation}
where $\mu_p^{(n)}$ and $\lambda_n$ are polymer viscosities and relaxation times, respectively. One can think of this process as descretizing the continuous spectrum of the fluid's relaxation times. We will now deduce a new formula for $\bfs$ by inserting this assumption. This yields
\begin{equation}
    \bfs(t)=\int_0^t\partial_\tau \bfb(t,t-\tau)\sum_{n=1}^{N}\mu_p^{(n)}e^{-\tau/\lambda_n}\D\tau.
\end{equation}
Because all $\mu_p^{(n)}$ are constant and the integral is linear we can rewrite this to read
\begin{equation}
    \bfs(t) = \sum_{n=1}^{N}\mu_p^{(n)}\int_0^t\partial_\tau \bfb(t,t-\tau)e^{-\tau/\lambda_n}\D\tau.
\end{equation}
We will now follow a similar pattern as we did in chapter \ref{ch:model}. We will use integration by parts. It results in
\begin{equation}
    \bfs(t)=\sum_{n=1}^{N}\left(\mu_p^{(n)}\bfb(t,0)e^{-t/\lambda_n}-\mu_p^{(n)}\bfb(t,t)+\frac{\mu_p^{(n)}}{\lambda_n}\int_0^t\bfb(t,t-\tau)e^{-\tau/\lambda_n}\D\tau \right).
\end{equation}
We can now use the initial condition for $\bfb$ to eliminate some terms. The integral can also be extended to $\infty$ without changing the value. We obtain
\begin{equation}
    \bfs(t)=\sum_{n=1}^N\frac{\mu_p^{(n)}}{\lambda_n}\int_0^\infty\bfb(t,t-\tau)e^{-\tau/\lambda_n}\D\tau.
\end{equation}
This integral is exactly the \textsc{Laplace} transform of $\bfb$. Therefore, the equation for $\bfs$ becomes
\begin{equation}
    \bfs(t)=\sum_{n=1}^N\frac{\mu_p^{(n)}}{\lambda_n}L_{\bfb}(t,1/\lambda_n)=\sum_{n=1}^N\mu_p^{(n)}\bfC_{1/\lambda_n}.
\end{equation}
If we look closely at the equation above one can see that we now have $N$ equations for $\bfC$ to simulate. So to calculate $\bfs$ we have to simulate 
\begin{equation}
    \partial_t \bfC_{1/\lambda_n}+\frac{1}{\lambda_n}\bfC_{1/\lambda_n}=\nabla u
\end{equation}
for all $n$. This increases the computational effort but should still be more efficient than brute force calculating the integral at every timestep. Because $G$ is just a linear combination, all proofs and statements we made about the simpler equation remain true for this one.
\section{A simple integral equation}
In this section we will take a look at a related integral equation. Later on the solution of this equation can be interpreted as the square root of the relaxation modulus $G$. More information on this equation can be found in \cite{Gnann2012} The new equation has the same complexity regarding the integral as the ones we were looking at earlier, but the complexity regarding dimension and number of equations is much reduced. This makes it easier to concentrate on the main problem and to gather ideas, how one may approach the problem of an integro-dfferential equation in general. We use 
\begin{align}
   \dot\phi(t)&=-\phi(t)-\int_0^tm(t-\tau)\dot\phi(\tau)\D\tau,\\
   m(t)&=v_1\phi(t)+v_2\phi(t)^2,
\end{align}
where we use the dot notation for the derivative and $v_1$ and $v_2$ are given constants. This equation is also studied in \cite{Goetze1995}.
The integral is the convolution of $m$ and $\dot\phi$. The convolution is symmetric and because $m(\tau)$ is independent of $t$ the derivative can be applied to the whole product instead of just $\phi$. This is allowed, because if $\phi$ is differentiable then, by definition, $m$ is as well. Using these ideas we get
\begin{equation}
    \dot\phi(t)=-\phi(t)-\int_0^t\frac{\D}{\D t}(m(\tau)\phi(t-\tau))\D\tau.
\end{equation}
If we apply the inverse Leibniz rule for parameter integrals, we can swap the integral and differential to obtain
\begin{equation}
    \dot\phi(t)=-\phi(t) -\frac{\D}{\D t}\int_0^t m(\tau)\phi(t-\tau)\D\tau +m(t)\phi(0)
\end{equation}
We can now integrate over $t$ to eliminate all derivatives. This leads to 
\begin{equation}
    \phi(t)=\phi(0)-\int_0^tm(t')\phi(t-t')\D t' +\int_0^tm(t')\phi(0)\D t' -\int_0^t\phi(t')\D t',
\end{equation}
where we renamed the integration variable to $t'$ to be able to shorten the expression. We obtain
\begin{equation}
    \phi(t)=\phi(0)+\int_0^t[m(t')(\phi(0)-\phi(t-t'))-\phi(t')]\D t'.\label{eq:phianalytic}
\end{equation}
Now we have a pure integral equation. The next step will be to discretize the integral and $t$.
We will use timesteps $0=t_0,\dotsc,t_N=T$, where $T$ is the end time. The timestep length is given by $h_j=t_{j+1}-t_j$, where $h_j$ does not have to be constant. For the integral we will use 
\begin{equation}
    \int_0^{t_n}f(t)\D t=\sum_{j=0}^{n-1}\int_{t_j}^{t_{j+1}}f(t)\D t\label{eq:generalint}
\end{equation}
for a generic $f$. We will denote $f_{n+1}:=f(t_{n+1})$. Now, we have to choose a method to calculate the integral in \eqref{eq:generalint}. By using a simple quadrature rule and $h_j\equiv \Delta t$, we obtain
\begin{equation}
    \phi_{n+1}=\phi_0 + \sum_{j=0}^{n}\left(\Delta t\, m_j\,(\phi_0-\phi_{n+1-j})-\phi_j\right).
\end{equation} We call this algorithm (A1).
One can observe that to calculate timestep $t_n$ from $t_{n-1}$ we need computational effort $\mathcal{O}(n)$. So to calculate $t_N$ from the start $t_0$ results in effort
\begin{equation}
    \sum_{n=1}^Nn=\frac{N(N+1)}{2},
\end{equation}
where we used the \textsc{Gaussian} summation rule. So it results that the calculation of $t_N$ from the initial condition results in $\mathcal{O}(N^2)$ effort.
But that is very inefficient so we will try to find a better method. However, we implemented this brute force approach to obtain a reference for the next algorithms.
\subsection{Exponentially increasing time intervals}
We try to employ, that the resulting solution $\phi$ is exponentially decaying. Therefore it makes sense that we use intervals that increase their size exponentially. We hope that this approach is successful because a similar trick is done in calculating the Fast-\textsc{Fourier}-Transformation. For more on this topic see \cite{Cooley1965}. So we set $t_j=h2^j$ and choose 
\begin{equation}
    \sum_{j=0}^{n-1}\int_{t_j}^{t_{j+1}}f(t)\D t\approx\sum_{j=0}^{n-1}(t_{j+1}-t_j)f_{j+1}.
\end{equation}
So we approximate the integral with the rectangle formed by the value on the right side and the interval length. This underestimates the true value because the function is monotonously decreasing. Replacing the integral in \eqref{eq:phianalytic} yields
\begin{equation}
    \phi_n = \phi_0 + \sum_{j=0}^{n-1}h_j[m_{j+1}(\phi_0-\phi(t_n-t_{j+1}))-\phi_{j+1}]\label{eq:phidisc}
\end{equation} 
If we take the same equation for $\phi_{n+1}$ and subtract \eqref{eq:phidisc} we obtain
\begin{equation}
    \phi_{n+1}= \phi_n -h_n\phi_{n+1}+\sum_{j=0}^{n-1}h_jm_{j+1}(\phi(t_n-t_{j+1})-\phi(t_{n+1}-t_{j+1}))\label{eq:phidiff}
\end{equation}
We run into a problem here because of the terms $\phi(t_n-t_{j+1})$ and $\phi(t_{n+1}-t_{j+1})$. Because the difference in the argument does not necessarily correspond to a point in time we already calculated, we have to interpolate this value. To choose sensible interpolation points, we check in which interval the differences would lie in. It yields
\begin{equation}
    t_n =h2^n\ge t_n-t_{j+1}=h(2^n-2^{j+1})\ge h(2^n-2^{n-1}) =h2^{n-1}=t_{n-1},
\end{equation}
where $0\le j\le n-2$. The case where $j=n-1$ is trivial and we will consider this term separately later on.
This means that the first term lies completely in the already known interval from the previous timestep. We use $\phi(t_n-t_{j+1})\approx\phi_n$ as an interpolation for all $0\le j\le n-2$. If we conduct the same calculations for $t_{n+1}-t_{j+1}$, we get
\begin{equation}
    t_{n+1}=h2^{n+1}\ge t_{n+1}-t_{j+1}\ge h(2^{n+1}-2^{n-1})=h\frac{3}{2}2^n=\frac{3}{2}t_n,
\end{equation}
where $0\le j\le n-2$ as before. This however presents the challenge, that we have to interpolate in the yet unknown interval $[t_{n+1},3/2t_{n}]$. As we want to obtain an implicit method we use $t_{n+1}$. Putting the assumptions for the interpolation into \eqref{eq:phidiff} we obtain
\begin{equation}
    \phi_{n+1}(1 + h_n + \sum_{j=0}^{n-2}h_jm_{j+1})=\phi_n(1+\sum_{j=0}^{n-2}h_jm_{j+1})+h_{n-1}m_n(\phi_0-\phi_n).
\end{equation}
If we now define $s_n:=\sum_{j=0}^{n-2}h_jm_{j+1}$, we can rewrite everything as
\begin{align}
    \phi_{n+1}(1+h_n+s_n)&=\phi_n(1+s_n-h_{n-1}m_n)+h_{n-1}m_n\phi_0,\\
    s_{n+1}&=s_n+h_{n-1}m_n.
\end{align}
We define $s_0=0$ as the initial condition of $s$. To obtain greater accuracy we should avoid the division of large numbers. Therefore we multiply the equation with $2^{-n}$. This results in
\begin{align}
    \phi_{n+1}(2^{-n}+h+2^{-n}s_n) &= \phi_n(2^{-n}+2^{-n}s_n-\frac{h}{2}m_n)+\frac{h}{2}m_n\phi_0,\\
    s_n=s_n+h_{n-1}m_n.
\end{align}
We introduce $\beta_n=2^{-n}s_n$. We obtain
\begin{align}
     \phi_{n+1}(2^{-n}+h+\beta_n) &= \phi_n(2^{-n}+\beta-\frac{h}{2}m_n)+\frac{h}{2}m_n\phi_0,\\
     \beta_{n+1} &= 2^{-n-1}s_{n+1}=\frac{1}{2}(\beta_n+\frac{h}{2}m_n) .
\end{align}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{Phidiff.pdf}
    \caption{Both $\phi$ with $h=\Delta t=0.01$ and $v_1=1.5,~v_2=0.5$}
    \label{fig:phifalse}
\end{figure}
This is now an explicit algorithm, called (A2) with $\mathcal{O}(N)$ to solve the equation for $\phi$. However as one can see in figure \ref{fig:phifalse}, it does not converge to the correct solution. Moreover it is unclear if for $h\to 0$ the error would become better as it would lead to $T-t_{N-1}\to T$. This means that this method is not suitable for our problem and we need to find a new approach.
\subsection{Transformation of the argument}
The reason that the previous method did not work was probably due to the fact that we eliminated the effect of the history completely. So we need an algorithm with a runtime between $\mathcal{O}(n)$ and $\mathcal{O}(n^2)$. The next idea one could follow is to transform $t=f(u)$ and $\tilde\phi(u)=\phi(f(u))$ (and $m$ accordingly), where $f$ is a diffeomorphism (bijective function with differentiable inverse).  Let $u_{-1}=f^{-1}(0)$, which is unique because $f$ is especially injective. If we recall \eqref{eq:phianalytic} and insert the transformation for $t$, we obtain
\begin{equation}
    \phi(f(u)) = \phi(f(u_{-1}))+\int_{u_{-1}}^{u}f'(u')[m(f(u'))(\phi(f(u_{-1}))-\phi(f(u)-f(u')))-\phi(f(u'))]\D u'.
\end{equation}
Now we can replace $\phi$ by $\tilde\phi$. The transformed equation reads
\begin{equation}
    \tilde{\phi}(u)=\tilde{\phi}(u_{-1}) +\int_{u_{-1}}^{u}f'(u')[\tilde{m}(u')(\tilde\phi(u_{-1})-\tilde{\phi}(f^{-1}(f(u)-f(u'))))-\tilde{\phi}(u')]\D u'.\label{eq:phitilde}
\end{equation}
The goal of this transformation is that we can use equally spaced points in $u$ and $u'$ but do not have effort $\mathcal{O}(N^2)$. The important term is $\tilde\phi(f^{-1}(f(u)-f(u')))$ because this is the only time that old timesteps effect the current one. Ideally 
\begin{equation}
    F(u,u'):=f^{-1}(f(u)-f(u'))\approx u,\quad u'\in(u_{-1},u]
    \end{equation}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{HistoryF.pdf}
    \caption{History dependency for different $f$ with $u=3$}
    \label{fig:Fustrich}
\end{figure}almost everywhere. This would again eliminate the history completely like in the previous example. In figure \ref{fig:Fustrich} $F(u')$ is shown for a fixed $u$. We can see that for both functions $f$ we have a long interval, in which $u=F(u,u')$ is a good approximation. \par 
Now let $f(u)=e^u$. We choose this because $F(u,u')$ is qualitatively the same function for every $u$ just translated. For $f(u)=\exp(u)$ we have
\begin{equation}
    F(u,u')=\log(\exp(u)-\exp(u')).
\end{equation}
This will help us immensely later on. We then have $u_{-1}=-\infty$. Obviously we cannot start our calculation at $-\infty$ so we introduce an arbitrary $u_0$ where $\abs{f(u_0)-f(-\infty)}$ is negligible. This is possible, because $\exp(u)\to 0$ as $u\to-\infty$. From there we introduce a discretization for $u$ as
\begin{equation}
    u_i = u_0+ih,\quad\forall i=0,\dotsc,N
\end{equation}
where $h = \frac{\log(T) -u_0}{N}$ is a fixed interval length and we stop at $u_N=\log(T)$, where $T$ is the end time and $N$ the given number of steps. Our goal now is to calculate values for $\tilde\phi(u_i)$ for all $i=1,\dotsc,N$. We assume that for all $i=0\dotsc,N$ we have
\begin{equation}
    \tilde\phi(u) \equiv \tilde\phi(u_i), \quad\forall u\in(u_{i-1},u_i].
\end{equation}
This is where we introduce the discretization error. The evaluation of the integral will be exact under this assumption. Let us now take a look back at \eqref{eq:phitilde} and look at the integral part by part. Let us assume we know the values for each $\tilde\phi(u_i)$ for $i\le n$ and want to calculate $\tilde\phi(u_{n+1})$. For the first part we get
\begin{equation}
    I_1:=\int_{-\infty}^{u_{n+1}}f'(u')\tilde{m}(u')\tilde\phi(-\infty)\D u'=\tilde\phi(-\infty)\sum_{i=0}^{n+1}\int_{u_{i-1}}^{u_i}f'(u')\tilde{m}(u')\D u'
\end{equation}
Assuming $\tilde{m}$ to be piecewise constant on the integration interval, this also holds for $\tilde{m}$. As such, jumps only occur on the integral boundary and we obtain
\begin{equation}
    I_1 = \tilde{\phi}(-\infty)\sum_{i=0}^{n+1}\tilde{m}(u_i)\int_{u_{i-1}}^{u_i}f'(u')\D u' = \tilde{\phi}(-\infty)\sum_{i=0}^{n+1}\tilde{m}(u_i)[f(u_i)-f(u_{i-1})].
\end{equation}
We set 
\begin{equation}
    I_1 = \tilde\phi(-\infty)[S(n)+\tilde{m}(u_{n+1})[f(u_{n+1})-f(u_n)]].
\end{equation}
This way we can perform an update for $S(n+1) = S(n)+\tilde{m}(u_{n+1})[f(u_{n+1})-f(u_n)]$ and  only use linear effort for this part. The summand for $n+1$ will have to be regarded separately because it is implicitly depending on the value of $\tilde\phi$ we are trying to calculate. We will actually discover later on that we can at worst obtain a cubic problem in $\tilde\phi(u_{n+1})$, which we will solve using \textsc{Newton's} method.
\par After we now handled the first part of the integral successfully we will take a look at the third part because the second will be the most challenging. Consider
\begin{equation}
    I_3:=-\int_{u_{-1}}^{u_{n+1}}f'(u')\tilde\phi(u')\D u' = -\sum_{i=0}^{n+1}\int_{u_{i-1}}^{u_i}f'(u')\tilde\phi(u')\D u'.
\end{equation} Using the same arguments as for $I_1$ we obtain
\begin{equation}
    I_3 = -\sum_{i=0}^{n+1}\tilde\phi(u_i)[f(u_i)-f(u_{i-1})] = -M(n) -\tilde\phi(u_{n+1})[f(u_{n+1})-f(u_{n})],
\end{equation}
with the update rule 
\begin{equation}
    M(n+1) = M(n) + \tilde\phi(u_{n+1})[f(u_{n+1})-f(u_{n})].
\end{equation}
To understand the second part we will first rename the integration variable to avoid confusion and arrive at
\begin{equation}
    I_2:=\int_{u_{-1}}^{u_{n+1}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v.
\end{equation}
Now let us recall the behavior of $F(u,v)$ in figure \ref{fig:Fustrich}. Heuristically, we can see that in the beginning we can set $\tilde\phi(F(u_{n+1},v))=\tilde\phi(u_{n+1})$. But what do we do with the remaining interval? To answer this question we observe that $F$ is its own inverse in the second argument. Let $x = F(u,v)$. It yields
\begin{equation}
    f(x)=f(u)-f(v)\quad\Rightarrow f(v)=f(u)-f(x)\quad\Rightarrow v= F(u,x).
\end{equation}
The remaining discretization will be built on this fact. Specifically, we set $w_i^n=F(u_n,u_i)$. This ensures that 
\begin{equation}
    \tilde\phi(F(u_{n+1},w^{n+1}_i))=\tilde{\phi}(u_j),
\end{equation}
for some $j=0,\dotsc,n$. Note that the $w_i^n$ are decreasing as $i$ increases for a fixed $n$. The lowest value of $w_i^n$ will be $w_{n-1}^n$. Our discretization $I_2$ will be 
\begin{equation}
    \{v_i\}_i=\text{sort}(\{u_i\}_i\cup \{w_i^{n+1}\}_i).
\end{equation}
In other word, the sequence $\{v_i\}$ is the union of the sequences on the right hand side but sorted. The sequence $\{v_i\}$ will differ in each timestep. One might be tempted to think that this will at least result in an $\mathcal{O}(N^2)$ algorithm because we have to sort in every timestep, but we will solve this issue later on.
\par An important thing to know during the simulation is the first index $j$ so that $v_j\in\{w_i^{n+1}\}_i$ for each $n$. Because we know that $v_j = w_{n}^{n+1}$ we can calculate this directly. We introduce the index
\begin{equation}
    l^*:=\left\lceil  \frac{u_n -w_{n}^{n+1}}{h}\right\rceil.
\end{equation}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Tranformls1}
    \caption{Visualization of the discretization for $I_2$, where $n=3$}
    \label{fig:vis1}
\end{figure}
This is constant in $n$ because of our choice for $f$ and equals the number of intervals, over which the $w_i^{n+1}$ spread. Therefore we know that all intervals until $u_{n-l^*+1}$ do not contain any points $w_i^{n+1}$.
 Figure \ref{fig:vis1} shows the discretization of $I_2$, where $n=3$. Both lines represent $[u_0,u_4]$. The top line shows the equidistant discretization used for $\tilde{m}$ and the bottom line shows the discretization for $\tilde\phi(F(u_{4},v))$ The value below the respective lines denote the discretization points. Above the respective lines one can see the values of the factors $\tilde{m}$ and $\tilde\phi(F(u_4,v))$ for that specific interval. In the case shown above we have $l^*=1$. As a next step, we will divide the integral $I_2$ to become
\begin{equation}
    I_2 = \int_{-\infty}^{u_{n-l^*+1}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v + \int_{u_{n-l^* +1}}^{u_{n+1}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v.
\end{equation}
We see that \begin{equation}
    \tilde\phi(F(u_{n+1},v))=\tilde\phi(u_{n+1})
\end{equation}
in the first part of this integral. So we get 
\begin{equation}
    I_2 = \tilde\phi(u_{n+1})\int_{-\infty}^{u_{n-l^*+1}}f'(v)\tilde{m}(v)\D v+ \int_{u_{n-l^* +1}}^{u_{n+1}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v.
\end{equation}
By using similar arguments like we used to modify $I_1$ and $I_3$, we can simplify this to 
\begin{equation}
    I_2 = \tilde{\phi}(u_{n+1})\sum_{i=0}^{n+1-l^*}\tilde{m}(u_i)[f(u_i)-f(u_{i-1})]+ \int_{u_{n-l^* +1}}^{u_{n+1}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v.
\end{equation}
We will denote the remaining integral by $I_{2,2}$. Let us introduce $j^*$ as the index of $w_i^{n}$ so that $w_{l^*-i}^{n+1}\in[u_n,u_{n+1}],\quad\forall i\ge j^*$. This can also be calculated in the preprocessing of the calculation by using the problem: Find $j^*$ such that
\begin{equation}
    \frac{u_{l^*}-w_{l^*-j^*}^{l^*}}{h}\le 1 \quad \text{and} \quad\frac{u_{l^*}-w_{l^*-j^*+1}^{l^*}}{h}\g 1.
\end{equation}
This is a well-defined problem because such $j^*$ always exists at timestep $l^*$. We can now divide $I_{2,2}$ to obtain
\begin{equation}
    I_{2,2}= \int_{u_{n-l^*+1}}^{w^{n+1}_{n-j^*}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v + \int_{w^{n+1}_{n-j^*}}^{u_{n+1}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v.
\end{equation}
However, because the second integral lies completely within $[u_n,u_{n+1}]$ we get 
\begin{align}
    I_{2,2}&=\int_{u_{n-l^*+1}}^{w^{n+1}_{n-j^*}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v \\&+\tilde{m}(u_{n+1})\sum_{i=0}^{n-j^*}\int_{w^{n+1}_{n-j^*-i}}^{w^{n+1}_{n-j^*-i-1}}f'(v)\tilde{\phi}(F(u_{n+1},v))\D v.
\end{align}
We assumed that $\tilde\phi$ is constant on each interval. Therefore we want $\tilde\phi(F(u_{n+1},v))$ to be $\tilde\phi(u_{n-j^*-i})$. We then obtain
\begin{align}
I_{2,2}&=\int_{u_{n-l^*+1}}^{w^{n+1}_{n-j^*}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v \\&+\tilde{m}(u_{n+1})\sum_{i=0}^{n-j^*}\tilde\phi(u_{n-j^*-i})[f(w^{n+1}_{n-j^*-i-1})-f(w_{n-j^*-i}^{n+1})]
\end{align}
If we recall the definition of $w$ we can simplify the expression to
\begin{align}
I_{2,2}&=\int_{u_{n-l^*+1}}^{w^{n+1}_{n-j^*}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v \\&+\tilde{m}(u_{n+1})\sum_{i=0}^{n-j^*}\tilde\phi(u_{n-j^*-i})[f(u_{n-j^*-i})-f(u_{n-j^*-i-1})].
\end{align}
By reordering the sum we obtain
\begin{equation}
    I_{2,2}=\int_{u_{n-l^*+1}}^{w^{n+1}_{n-j^*}}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v +
    \tilde{m}(u_{n+1})\sum_{i=0}^{n-j^*}\tilde\phi(u_{i})[f(u_i)-f(u_{i-1})].
\end{equation}
We can directly identify how the integral over the interval $[u_{n+1-l^*},w^{n+1}_{n}]$ should be calculated. We obtain 
\begin{equation}
    \int_{u_{n-l^*+1}}^{w^{n+1}_n}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v = \tilde\phi(u_{n+1})\tilde{m}(u_{n-l^*+2})[f(w^{n+1}_n)-f(u_{n-l^*+1})].
\end{equation}
But it holds
\begin{equation}
    f(w^{n+1}_n)=f(u_{n+1})-f(u_n).
\end{equation}
So it yields
\begin{align}
     \int_{u_{n-l^*+1}}^{w^{n+1}_n}f'(v)\tilde{m}(v)\tilde{\phi}(F(u_{n+1},v))\D v = \tilde\phi(u_{n+1})\tilde{m}(u_{n-l^*+2})[f(u_{n+1})-f(u_n)-f(u_{n-l^*+1})].
\end{align}
So what remains of the integral is the part, where the two discretizations overlap. We also have to discuss how we can eliminate the sorting process from the main loop as this would result in $\mathcal{O}(n^2\log(n))$ effort. We know that after calculating $l^*$ time steps we have the first appearance of a $w$ which is larger than $u_0$ and therefore needs consideration. But this is independent of $n$ and can be calculated in advance as a result. The part of $w$ which overlaps with the equidistant discretization is exactly the part that is not entirely in the interval $[u_n,u_{n+1}]$. So it is given by
\begin{equation}
    w^{l^*}_{l^*-i},\quad\forall i=1,\dotsc,j^*.
\end{equation}
Because the $u_i$ are equally spaced, we know that
\begin{equation}
    u_{n+1}=u_{l^*}+u_{n+1-l^*}.
\end{equation}
We can therefore add $u_{n+1-l^*}$ each timestep and obtain the current position of these $w$s. For each $n$ we know that the points $u_{n+1-l^*},\dotsc,u_n$ overlap with the other discretization. By applying the shift backwards we find that the $w$ as above overlap with 
\begin{equation}
    u_i,\quad\forall i=1,\dotsc,l^*-1.
\end{equation}
This way we can define the overlapping points 
\begin{equation}
    \tilde{u}= \bigcup_{i=1}^{l^*-1}u_i\,\cup\,\bigcup_{j=1}^{j^*}w^{l^*}_{l^*-j}
\end{equation}
We can sort the $\tilde(u)$ in the preprocessing. If we keep the permutation array that resulted during the sorting process, we can later recall, from which discretization each point came. We introduce two new variables
\begin{equation}
    q_i:=\abs{\{u_j\colon u_j\in\tilde{u} \text{ and }u_j\le\tilde{u_i} \}},\quad
    y_i:=\abs{\{w^{l^*}_j\colon w^{l^*}_j\in\tilde{u} \text{ and }w^{l^*}_j\le\tilde{u_i} \}}.
\end{equation}
Now we gathered all the information we need in the preprocessing, we can get back to $I_{2,2}$. With the new defined variables inserted, we obtain
\begin{align}
    I_{2,2}&= \sum_{i=1}^{l^*+j^*-1}\tilde{m}(u_{n+2-l^*+q_{i-1}})\tilde{\phi}(u_{n+1-y_{i-1}})[f(u_{n+1-l^*}+\tilde{u_i})-f(u_{n+1-l^*}+\tilde{u}_{i-1})]\\&+\tilde{m}(u_{n+1})\sum_{i=0}^{n-j^*}\tilde\phi(u_{i-1})[f(u_i)-f(u_{i-1})] \\&+ \tilde\phi(u_{n+1})\tilde{m}(u_{n-l^*+2})[f(u_{n+1})-f(u_n)-f(u_{n-l^*+1})].
\end{align}
Every term of \eqref{eq:phitilde} has been discretized. The whole discretization is obtained by calculating
\begin{equation}
    \tilde\phi(u_{n+1})=\tilde\phi(-\infty) + I_1 -I_2 +I_3.
\end{equation}
This computation yields
\begin{align}
    \tilde\phi(u_{n+1})&=\tilde\phi(-\infty) +\tilde\phi(-\infty)[S(n)+\tilde{m}(u_{n+1})[f(u_{n+1})-f(u_n)]]\label{eq:discphit1}\\&-M(n)\label{eq:discphit2} -\tilde\phi(u_{n+1})[f(u_{n+1})-f(u_{n})]  -\tilde{\phi}(u_{n+1})\sum_{i=0}^{n+1-l^*}\tilde{m}(u_i)[f(u_i)-f(u_{i-1})]\\&- \tilde\phi(u_{n+1})\tilde{m}(u_{n-l^*+2})[f(u_{n+1})-f(u_n)-f(u_{n-l^*+1})] \\&\label{eq:discphit3}-\sum_{i=1}^{l^*+j^*-1}\tilde{m}(u_{n+2-l^*+q_{i-1}})\tilde{\phi}(u_{n+1-y_{i-1}})[f(u_{n+1-l^*}+\tilde{u_i}-u_0)-f(u_{n+1-l^*}+\tilde{u}_{i-1}-u_0)]\\&\label{eq:discphit4}-\tilde{m}(u_{n+1})\sum_{i=0}^{n-j^*}\tilde\phi(u_{i})[f(u_i)-f(u_{i-1})],
\end{align}
where we have
\begin{equation}
    S(n+1) = S(n)+\tilde{m}(u_{n+1})[f(u_{n+1})-f(u_n)]
\end{equation}
and 
\begin{equation}
    M(n+1) = M(n) + \tilde\phi(u_{n+1})[f(u_{n+1})-f(u_{n})].
\end{equation}
As initial condition we set $S(-1)=M(-1)=0$. However due to the sums in \eqref{eq:discphit2} and \eqref{eq:discphit4}, we still have quadratic effort. But this can be avoided by introducing 
\begin{equation}
    O(n):=\sum_{i=0}^{n+1-l^*}\tilde{m}(u_i)[f(u_i)-f(u_{i-1})]
\end{equation}
and 
\begin{equation}
    Q(n):=\sum_{i=j^*}^{n-j^*}\tilde\phi(u_{i})[f(u_i)-f(u_{i-1})]+\tilde\phi(f(u_0-h(j^*+1)))
\end{equation}
with the update rules
\begin{equation}
O(n+1) = O(n)+\tilde{m}(u_{n+2-l^*})[f(u_{n+2-l^*})-f(u_{n+1-l^*})]
\end{equation}
and 
\begin{equation}
Q(n+1) = Q(n) + \tilde\phi(u_{n+1-j^*})[f(u_{n+1-j^*})-f(u_{n-j^*})].
\end{equation}
The variables $O$ and $Q$ are well defined because $l^*$ and $j^*$ are at least 1. In this deduction we always assumed $n+1-l^*>0$. But this is false for the first steps in the simulation. Therefore we will define
\begin{equation}
    O(n)= O(n-1)+\tilde{m}(-\infty)[f(u_0+(n+1-l^*)h)-f(u_0+(n-l^*)h]
\end{equation}
and 
\begin{equation}
Q(n)= Q(n-1)+\tilde{\phi}(-\infty)[f(u_0+(n-j^*)h)-f(u_0+(n-1-j^*)h)]
\end{equation}
for $n<l^*-1$ and $n<j^*$ respectively. As initial values we use 
\begin{equation}
    O(-1) = \tilde{m}(-\infty)f(u_0-hl^*)
\end{equation}
and
\begin{equation}
    Q(-1) = \tilde{\phi}(-\infty)f(u_0-h(j^*+1))
\end{equation}
to obtain the correct results.
Putting $O$ and $Q$ into \eqref{eq:discphit1} to \eqref{eq:discphit4} yields
\begin{align}
    \tilde\phi(u_{n+1})&=\tilde\phi(-\infty) +\tilde\phi(-\infty)[S(n)+\tilde{m}(u_{n+1})[f(u_{n+1})-f(u_n)]]\\&-M(n) -\tilde\phi(u_{n+1})[f(u_{n+1})-f(u_{n})] -\tilde{\phi}(u_{n+1})O(n)-\tilde{m}(u_{n+1})Q(n)\\&-\tilde\phi(u_{n+1})\tilde{m}(u_{n-l^*+2})[f(u_{n+1})-f(u_n)-f(u_{n-l^*+1})] \\&-\sum_{i=1}^{l^*+j^*-1}\tilde{m}(u_{n+2-l^*+q_{i-1}})\tilde{\phi}(u_{n+1-y_{i-1}})[f(u_{n+1-l^*}+\tilde{u_i}-u_0)-f(u_{n+1-l^*}+\tilde{u}_{i-1}-u_0)].
\end{align}
The sum in the last equation above will yield a quadratic and linear term in $\tilde{\phi}(u_{n+1})$ so we will split it up. This way we obtain
\begin{align}
   \tilde\phi(u_{n+1})&=\tilde\phi(-\infty) +\tilde\phi(-\infty)[S(n)+\tilde{m}(u_{n+1})[f(u_{n+1})-f(u_n)]]\\&-M(n) -\tilde\phi(u_{n+1})[f(u_{n+1})-f(u_{n})] -\tilde{\phi}(u_{n+1})O(n)-\tilde{m}(u_{n+1})Q(n)\\&-\tilde\phi(u_{n+1})\tilde{m}(u_{n-l^*+2})[f(u_{n+1})-f(u_n)-f(u_{n-l^*+1})] \\&-\sum_{i=1}^{l^*+j^*-2}\tilde{m}(u_{n+2-l^*+q_{i-1}})\tilde{\phi}(u_{n+1-y_{i-1}})[f(u_{n+1-l^*}+\tilde{u_i}-u_0)-f(u_{n+1-l^*}+\tilde{u}_{i-1}-u_0)]\\&-\tilde{m}(u_{n+1})\tilde{\phi}(u_{n+1-j^*})[f(w^{n+1}_{n+1-j^*})-f(u_n)].
\end{align}
\begin{table}
    \centering
    \begin{tabular}{c|c|c|c|c}
        \# Elements & $\mathrm{L}^2$-error&EOC in $\mathrm{L}^2$&$\mathrm{L}^\infty$-error &EOC in $\mathrm{L}^\infty$\\
        \hline
        50 & 1.29927 & - & 0.0250247  & -\\
        100 & 0.450672 & 1.5275475676992607 & 0.0101168 & 1.3066064275748301\\
        200 & 0.153403 & 1.5547536813705434 & 0.00407696 &1.311182153107891\\
        400 & 0.0558441 & 1.4578457386762156 & 0.0017411 &1.2274971804453685\\
        800 & 0.0222726 & 1.3261379803853823 & 0.00147244  &0.2417923432251396
    \end{tabular}
    \caption{Convergence of the new algorithm for the simpler integral equation}
    \label{tab:integral}
\end{table}
One can observe that $l^*=1$ is a special case because then we obtain a cubic problem in $\tilde\phi$. Otherwise the problem becomes quadratic. In the code this problem will be solved using \textsc{Newton's} method. If we compare the results that this algorithms produces with the one, which has $\mathcal{O}(N^2)$ runtime, we obtain table \ref{tab:integral}. One can clearly observe that convergence is obtained in both norms. Because we used constant ansatz functions we would expect an order of 1. Possibly, because we approximated the history integral with a much higher order, we obtain a slightly better convergence. This effect becomes less relevant the more elements we use. To understand the values for the $L^\infty$ norm we have to recall that we do not compare our results to a known exact solution but we rather compare it to another approximation by an algorithm we trust. This can explain the drop in order of convergence for the $L^\infty$ norm. \par 
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{runtime.pdf}
    \caption{Relationship of $l^*$ and $N$}
    \label{fig:runtime}
\end{figure}
The last thing to consider is the computational effort of this method. One might be tempted to think of linear runtime. However, $l^*$ and $j^*$ increase as $h$ decreases and $h$ decreases only as $N$ increases for a fixed end time $T$. A priori we cannot give a formula for this so we will empirically take a look at this relationship in figure \ref{fig:runtime}. This clearly shows a linear relationship in $l^*$. This leads to a $\mathcal{O}(N^2)$ algorithm. However, every time step within one discretization takes the same amount of time. The brute force algorithm on the other hand slows down from time step to time step. In the outlook given in chapter 6, we will discuss possibilities, which could improve the newly developed algorithm.

\chapter{Conclusion and Outlook}
In this chapter we will wrap up all results we obtained throughout this work and give an idea for future research in this topic. \par 
In the introduction we formulated the goal to be the development of an efficient method to simulate the governing equations for non-\textsc{Newtonian} fluids in two spatial dimensions. This was achieved using the \textsc{Laplace} transform to eliminate the bothering integral from the governing equations completely. The resulting algorithm is as efficient as a normal CFD simulation. We could simulate the cross section of a rheometer, which has practical value. Theoretical existence and uniqueness of the solution to the governing equation could be shown for a sensible set of parameters. Even though this could not be shown for $\mu_s=0$ we saw empirical convergence in the numerical experiments. \par 
The second thing we looked at was the possibility to solve the integral from the governing equations without the \textsc{Laplace} transform to be able to loosen some of the necessary assumptions. To accomplish this we studied the equation from \cite{Gnann2012}. Three approaches have been considered:
\begin{itemize}
    \item brute force
    \item exponentially increasing time intervals
    \item transformation of the argument
\end{itemize}
However, all of them were not perfectly suited. The first and third approach have a computational effort of $\mathcal{O}(N^2)$ and would therefore not be appropriate for an extension to the five-dimensional system of equations with a sensible number of degrees of freedom. The second approach did unfortunately not lead to a correct solution as the calculation error was to great. \\
\par 
For future research it might be worth to take a look at our newly developed algorithm from the third approach again. In it current state in timestep $n\to n+1$ $n$ history points are considered. Maybe one could carefully choose a subset of them and still obtain a good approximation? Another point to consider could be the difficulties that arise by introducing nonlinearity into the equations by either increasing the spatial dimension or allowing more flow directions. The theoretical existence of a solution might be interesting to study for this case. Another possibility to enhance the newly developed algorithm could lie in the choice of $f$. We saw in figure \ref{fig:Fustrich} that $f(u)=\exp(\pi/2\sinh(u))$ has better properties regarding the history dependency. However, $F(u,u')$ then becomes heavily dependent on $u$ and introduces new effort each timestep.\\
\par 
All in all, one can say that for a spatial two-dimensional problem with one flow direction and a memory function of special form we could present an efficient algorithm. For a related equation, we studied some approaches that can be a good starting point for further studies.
\addcontentsline{toc}{chapter}{List of Figures}
\setcounter{lofdepth}{2}
\listoffigures
\newpage
\addcontentsline{toc}{chapter}{List of Tables}
\setcounter{lofdepth}{2}
\listoftables
\newpage
\addcontentsline{toc}{chapter}{References}
\bibliographystyle{amsplain}
\bibliography{References}{}
\newpage
\begin{otherlanguage}{ngerman}
\chapter*{Eigenständigkeitserklärung}
Hiermit versichere ich an Eides statt, dass ich die vorliegende Arbeit selbstständig und ohne die Benutzung anderer als der angegebenen  Hilfsmittel  angefertigt  habe.  
Alle  Stellen,  die  wörtlich  oder  sinngemäß  aus  veröffentlichten  und  nicht  veröffentlichten  Schriften  entnommen  wurden,  sind  als  solche  kenntlich  gemacht.  
Die  Arbeit  ist  in  gleicher  oder  ähnlicher  Form  oder  auszugsweise  im  Rahmen  einer  anderen  Prüfung  noch  nicht  vorgelegt  worden. 
Ich  versichere,  dass  die  eingereichte    elektronische    Fassung    der    eingereichten    Druckfassung    vollständig    entspricht.
\\[\bigskipamount]
Köln, \today
\\[2\bigskipamount]
Nils Dornbusch
\end{otherlanguage}

\end{document}
